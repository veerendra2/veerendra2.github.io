[{"content":"Introduction Hello guys, today I came up with an interesting write up, that is how to setup backup and restore with Velero on Kubernetes. A year back I worked on Strimzi Kafka, a deployment solution for deploying production level Kafka on Kubernetes. Strimzi Kafka uses persistance volume(PV) as a disk which is a managed disk from cloud provider(e.g. Azure, AWS, etc), but I couldn\u0026rsquo;t find proper backup solution in order to configure PV backup and restore. Sure, you can configure these managed disk backups from Terraform or manually in cloud provider portals. But tools like Velero, backups PV from kubernetes side which is more visible and easy to manage which is what you will see in a moment.\n❗ Velero supports multiple cloud provider, this write up covers only deployment of Velero on kubernetes with storage class provisioner as AzureDisk\n👉 All deployment files are in my repo https://github.com/veerendra2/velero-demo\nVelero https://velero.io\nVelero is an open source tool to safely backup and restore, perform disaster recovery, and migrate Kubernetes cluster resources and persistent volumes\nDisaster Recovery → Reduces time to recovery in case of infrastructure loss, data corruption, and or service outage Data Migration → Enables cluster portability by easily migrating Kubernetes resources from one cluster to another. Data Protection → Offers key data protection features such as scheduled backups, retention schedules, and pre or post-backup hooks for custom actions. Features Backup Clusters Backup your Kubernetes resources and volumes for an entire cluster, or part of a cluster by using namespaces or label selectors. Schedule Backups Set schedules to automatically kickoff backups at recurring intervals. Backup Hooks Configure pre and post-backup hooks to perform custom operations before and after Velero backups. How it works ┌ │ │ │ │ │ │ │ │ │ └ ─ ─ ─ ─ ─ ┌ │ │ │ │ └ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┬ │ │ └ ─ ─ ─ V ─ a ─ ─ ─ ─ e ─ z ─ K ─ ─ ─ l ─ m u ─ u ─ ─ ─ e ─ i r ─ b ─ ─ ─ r ─ c e ─ e ─ ─ ─ o ─ r ─ r ─ ─ ─ ─ o p ─ n ─ ─ ─ S ─ s l ─ e ─ ─ ─ e ─ o u ─ t ─ ─ ─ r ─ f g ─ e ─ ─ ─ v ─ t i ─ s ─ ─ ─ e ─ n ─ ─ ─ ─ r ─ ─ ─ ─ ─ ┬ │ │ ┘ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┐ │ ├ │ ├ ┘ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┐ │ │ ┼ │ ┼ │ | │ │ │ ┘ m ─ ─ e ─ ─ P b t ─ ─ e a a ─ ─ r c a d ─ ─ s k p a ─ ─ i u p t ─ ─ s p s a ─ ─ t ─ ─ a m d b ─ ─ n a e a ─ ─ c n p c ─ ─ e a l k ─ ─ - g o u ─ ─ v e y p ─ ─ o m m ─ ─ l e e m ─ ─ u n n a ─ ─ m t t n ─ ─ e a ─ ┐ │ │ └ g ─ ─ e ─ ─ m ─ ─ e ─ ─ n ─ ─ t ► ► ┌ │ │ └ ┌ │ | └ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ M ─ ─ ─ ─ a ─ ─ A ─ ─ n ─ ─ z ─ ─ A a ─ ─ u S ─ ─ z g ─ ─ r t ─ ─ u e ─ ─ e o ─ ─ r d ─ ─ r ─ ─ e ─ ─ B a ─ ─ D ─ ─ l g ─ ─ i ─ ─ o e ─ ─ s ─ ─ b ─ ─ k ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┐ │ │ ┘ ┐ │ │ ┘ Velero uses service principle to access cloud resources for managing backups of deployments on K8s. It supports various plugins for cloud, while deploying Velero we have to specify plugin and provide credentials(/base/deployment.yaml#L67). By using Velero, we can backup deployments, PVs, namespaces and entire clusters.\nFor deployment related backups, it uses storage account to store all deployments metadata For PV backup, it uses a snapshot from the cloud provider. ⚠️ Backups may fails sometimes, if it doesn\u0026rsquo;t have necessary memory(#3234)\nArchitecture Below diagram gives bird eye view on how Velero works Deploy Velero provides binary to manage kubernetes deployment and scheduled backups. But, in our deployment, we do something different, that is to use kustomize and manage in git repo. But first we need to download velero binary from release page here\n$ curl -O https://github.com/vmware-tanzu/velero/releases/download/v1.9.1/velero-v1.9.1-linux-amd64.tar.gz $ tar -xf velero-v1.9.1-linux-amd64.tar.gz $ cd velero-v1.9.1-linux-amd64/ $ ls examples LICENSE velero $ sudo mv velero /usr/local/bin/ Prerequisites Before deploying Velero server on kubernetes, we need to customize the velero server according to our needs. Below is the configuration for Velero to manage Azure resources.\nBelow are the variables that will be used during installation\nEnvironmental Variable Name Description SUBSCRIPTION_ID Subscription ID TENANT_ID Tenant ID of service principle CLIENT_ID Client ID of service principle CLIENT_SECRET Service principal secret RESOURCE_GROUP Source resource groups where K8s PVs(Azure Managed Disks) are present to backup BACKUP_RESOURCE_GROUP Destination resource group where PV(Azure Managed Disks)snapshots are stored STORAGE_ACCOUNT_ID Storage account name BLOB_CONTAINER Container name in storage account where K8s deployment metadata stored BACKUP_SUBSCRIPTION_ID Subscription ID where backs are stored(In our case, this value SUBSCRIPTION_ID) STORAGE_ACCOUNT_ACCESS_KEY Storage account access key CLOUD_NAME Cloud name, the value is AzurePublicCloud Create service principal $ az account list --query \u0026#34;[].{name:name, id:id}\u0026#34; --output tsv $ export SUBSCRIPTION_ID=\u0026#34;[SUBSCRIPTION_ID_HERE]\u0026#34; $ az login $ CLIENT_SECRET=`az ad sp create-for-rbac --name \u0026#34;velero-sp\u0026#34; --role\u0026#34;Contributor\u0026#34; --query \u0026#39;password\u0026#39; -o tsv --scopes subscriptions/$SUBSCRIPTION_ID` $ CLIENT_ID=`az ad sp list --display-name \u0026#34;velero-sp\u0026#34; --query\u0026#39;[0].appId\u0026#39; -o tsv` $ TENANT_ID=`az ad sp list --display-name \u0026#34;velero-sp\u0026#34; --query\u0026#34;[].appOwnerTenantId\u0026#34; -o tsv Create Azure storage account $ az storage account create \\ --name $STORAGE_ACCOUNT_ID \\ --resource-group $RESOURCE_GROUP \\ --location \u0026lt;location\u0026gt; \\ --sku Standard_ZRS \\ --encryption-services blob $ az storage container create \\ --account-name STORAGE_ACCOUNT_ID \\ --name $BLOB_CONTAINER \\ --auth-mode login Set Variables Below are dummy values of variables.\n$ cat \u0026lt;\u0026lt; EOF \u0026gt; ./credentials-velero SUBSCRIPTION_ID=\u0026#34;my-sub-id\u0026#34; TENANT_ID=\u0026#34;my-tnt-id\u0026#34; CLIENT_ID=\u0026#34;my-client-id\u0026#34; CLIENT_SECRET=\u0026#34;secure-secret\u0026#34; RESOURCE_GROUP=\u0026#34;myresgrp\u0026#34; CLOUD_NAME=AzurePublicCloud EOF $ export BACKUP_RESOURCE_GROUP=myresgrp $ export STORAGE_ACCOUNT_ID=myaccount $ export BACKUP_SUBSCRIPTION_ID=my-sub-id $ export BLOB_CONTAINER=backup Generate Deployment Files Once variables are set and verified, generate kubernetes deployment files using velero cli\n❗ You can also get the velero deployment here\n$ velero install \\ --provider azure \\ --plugins velero/velero-plugin-for-microsoft-azure:v1.1.0 \\ --bucket $BLOB_CONTAINER \\ --secret-file ./credentials-velero \\ --backup-location-config resourceGroup=$BACKUP_RESOURCE_GROUP,storageAccount=$STORAGE_ACCOUNT_ID,subscriptionId=$BACKUP_SUBSCRIPTION_ID \\ --snapshot-location-config apiTimeout=5m,resourceGroup=$BACKUP_RESOURCE_GROUP,subscriptionId=$BACKUP _SUBSCRIPTION_ID \\ --use-volume-snapshots=true --dry-run -o yaml ... Once you run the above command, it displays deployment files on stdout, because of the --dry-run -o yaml option. Copy the content to separate yaml files like below.\n👉 You can check here how I seperated https://github.com/veerendra2/velero-demo/tree/main/base\n## https://github.com/veerendra2/velero-demo/tree/main/base $ tree . . ├── cluster-role-binding.yaml ├── deployment.yaml └── velero-crds.yaml 0 directories, 3 files Once all files are arranged(and verify variables in below deployment files that we configured in above section), login into kubernetes and run the deployment one-by-one\n$ kubectl create -f velero-crds.yaml $ kubectl create -f cluster-role-binding.yaml $ kubectl create -f deployment.yaml Kubernetes deploys the velero server in the velero namespace as a pod. Verify velero server is installed with kubectl get pods -n velero\nConfigure Backups We can configure backups with velero cli\n❗ A handy tool to write cronjob -\u0026gt; https://crontab.guru/\n$ velero schedule create kafka-backup-schedule \\ --schedule=\u0026#34;@every 168h\u0026#34; --ttl 2160h0m0s \\ --include-namespaces=kafka $ velero schedule get NAME STATUS CREATED SCHEDULE BACKUP TTL LAST BACKUP SELECTOR kafka-backup-schedule Enabled 2020-11-21 20:35:04 +0100 STD 0 15 * * 5 2160h0m0s 1d ago \u0026lt;none\u0026gt; The above example, backups all resources in namespace kafka(including PVs and K8s deployment files) for every 168 hours. But we want setup every thing in yaml files so that we store in git repo(e.g. /overlay/dev). So, we can ask velero cli to display yaml like below\n$ velero schedule create kafka-backup-schedule --schedule=\u0026#34;@every 168h\u0026#34; --ttl 2160h0m0s--include-namespaces=kafka -o yaml apiVersion: velero.io/v1 kind: Schedule metadata: creationTimestamp: null name: kafka-backup-schedule namespace: kafka spec: schedule: \u0026#39;@every 168h\u0026#39; template: hooks: {} includeClusterResources: true includedNamespaces: - \u0026#39;*\u0026#39; ttl: 2160h0m0s status: {} You can also look for help like below\n$ velero schedule create --help The --schedule flag is required, in cron notation, using UTC time: | Character Position | Character Period | Acceptable Values | | ------------------ | :--------------: | ----------------: | | 1 | Minute | 0-59,* | | 2 | Hour | 0-23,* | | 3 | Day of Month | 1-31,* | | 4 | Month | 1-12,* | | 5 | Day of Week | 0-7,* | The schedule can also be expressed using \u0026#34;@every \u0026lt;duration\u0026gt;\u0026#34; syntax. The duration can be specified using a combination of seconds (s), minutes (m), and hours (h), for example: \u0026#34;@every 2h30m\u0026#34;. Usage: velero schedule create NAME --schedule [flags] We can get backup status if the schedule that we configured above.\n$ velero schedule get NAME STATUS CREATED SCHEDULE BACKUP TTL LAST BACKUP SELECTOR kafka-backup-schedule Enabled 2020-11-21 20:35:04 +0100 STD 0 15 * * 5 2160h0m0s 1d ago \u0026lt;none\u0026gt; $ velero backup get NAME STATUS CREATED EXPIRES STORAGE LOCATION SELECTOR kafka-backup-schedule-20201121202523 Completed 2020-11-21 21:25:23 +0100 STD 88d default \u0026lt;none\u0026gt; kafka-backup-schedule-20201121201523 Completed 2020-11-21 21:15:23 +0100 STD 88d default \u0026lt;none\u0026gt; ❗ schedule consists of multiple backup as you can see above\nOnce everything is setup we can do magic with kustomize. So, below is finally show off with kustomize. This kustomize setup is very useful when you configure with GitOps tools like Argo CD.\n👉 You can find this demo deployment files in my repo here https://github.com/veerendra2/velero-demo\n$ tree . . ├── base │ ├── cluster-role-binding.yaml │ ├── deployment.yaml │ ├── kustomization.yaml │ └── velero-crds.yaml ├── overlay │ └── dev │ ├── backup-locations.yaml │ ├── backup-schedules │ │ └── pvc.yaml │ ├── kustomization.yaml │ └── secrets │ └── cloud-credentials.yaml └── README.md 5 directories, 9 files Terminology Before concluding this write up, we need to get familiar with 2 terminologies that helps us to understand how Velero works internally\nBackup Storage Location The BackupStorageLocation holds info about storage account, container in storage account. We can have multiple \u0026ldquo;Backup Storage Location\u0026rdquo; with difference containers and storage account(e.g. dev/backup-locations.yaml#L2-L15)\n## Since there velero CRDs are installed, we can query like below $ kubectl get backupstoragelocations -n velero NAME AGE default 1d kafka 1d Volume Snapshot Location The VolumeStorageLocation holds info about resource group where snapshots are stored(e.g. dev/backup-locations.yaml#L17-L21)\n## Since there velero CRDs are installed, we can query like below $ kubectl get volumesnapshotlocations -n velero NAME AGE default 1d Restore What good is the backup if you can\u0026rsquo;t restore?!\u0026hellip;\nGet schedule and backup like below\n## Login into kubernetes with kubectl cli $ velero schedule get NAME STATUS CREATED SCHEDULE BACKUP TTL LAST BACKUP SELECTOR kafka-backup-schedule Enabled 2020-11-21 20:35:04 +0100 STD 0 15 * * 5 2160h0m0s 1d ago \u0026lt;none\u0026gt; $ velero backup get NAME STATUS CREATED EXPIRES STORAGE LOCATION SELECTOR kafka-backup-schedule-20201121202523 Completed 2020-11-21 21:25:23 +0100 STD 88d default \u0026lt;none\u0026gt; Create restore\n$ velero restore create --from-backup kafka-backup-schedule-20201121202523 Restore request \u0026#34;kafka-backup-schedule-20201121202523-20201123033701\u0026#34; submitted successfully. Run `velero restore describe kafka-backup-schedule-20201121202523-20201123033701` or `velero restore logs kafka-backup-schedule-20201121202523-20201123033701` for more details. We can also describe to know the status\n$ velero restore describe kafka-backup-schedule-20201121202523-20201123033701 Name: kafka-backup-schedule-20201121202523-20201123033701 Namespace: velero Labels: \u0026lt;none\u0026gt; Annotations: \u0026lt;none\u0026gt; Phase: InProgress \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;----STATUS-HERE Backup: kafka-backup-schedule-20201121202523 Namespaces: Included: all namespaces found in the backup Excluded: \u0026lt;none\u0026gt; Resources: Included: * Excluded: nodes, events, events.events.k8s.io, backups.velero.io, restores.velero.io, resticrepositories.velero.io Cluster-scoped: auto Namespace mappings: \u0026lt;none\u0026gt; Label selector: \u0026lt;none\u0026gt; Restore PVs: auto Once restore is completed, verify has it been restored\n$ kubectl get pods -n kafka ... Conclusion In this write up, I have covered\nSneak peek on Velero How Velero works How to deploy and configure to manage resources on Azure. Configure scheduled backups Restore BONUS; I have collected handfull of velero cli example in my Github gist here Stay tuned, my next write up will be published very soon which is related to backup and restore on Kubernetes 😃\n","permalink":"https://veerendra2.github.io/posts/velero-deployment/","summary":"Introduction Hello guys, today I came up with an interesting write up, that is how to setup backup and restore with Velero on Kubernetes. A year back I worked on Strimzi Kafka, a deployment solution for deploying production level Kafka on Kubernetes. Strimzi Kafka uses persistance volume(PV) as a disk which is a managed disk from cloud provider(e.g. Azure, AWS, etc), but I couldn\u0026rsquo;t find proper backup solution in order to configure PV backup and restore.","title":"Velero Deployment with Kustomize (Azure)"},{"content":"It has been 2 year since I wrote a new post. Due to busy work, moving to a new city, new jobs and getting married, I wasn’t able to keep up posts. Finally I’m back now, I have been thinking of changing blog themes for a long time. I spent some time on exploring Jekyll themes and tried to modify them according to my requirements. As you can see here github issue.\nHugo But a month ago I discovered Hugo, a static website builder like Jekyll, so I decided to take a look at it. And thus I decided to move to Hugo, because of its speed, simple and single binary\nJust like Hugo, I discovered Jekyll a few years back, as you can see from my old blog post. After using Jekyll for a while I see below annoying things while building and installing Jekyll everytime I change the OS in my laptop. #7\nJekyll is relatively slow I get confuse with gems versions and its dependencies while picking new themes Screw up my system ruby packages with other packages like Vagrant etc. because of that I had to use docker containers and these some permissions issues, etc. So, when I see Hugo, it solved my above problems\nIt is faster like they say in their website To install new theme, I can use git module or simply drop the theme in themes directly and configure Single binary! No BS! Simple directory structure Now my blog is powered by Hugo 🎉\nOther updates I removed disqus tool for commenting, moved to Github discussion with tool https://giscus.app From now onwards I will try to keep up the blogs regularly. I’m planning some “nugget” blogs like small posts contains info from book I’m reading or may be some my troubleshooting on tools, etc. 🤞 ","permalink":"https://veerendra2.github.io/posts/moving-to-hugo/","summary":"It has been 2 year since I wrote a new post. Due to busy work, moving to a new city, new jobs and getting married, I wasn’t able to keep up posts. Finally I’m back now, I have been thinking of changing blog themes for a long time. I spent some time on exploring Jekyll themes and tried to modify them according to my requirements. As you can see here github issue.","title":"Moving to Hugo and other updates!"},{"content":"Looks like my blog posts are like Sherlock TV Show episodes, posting once in a while..anyways I\u0026rsquo;m back now. As you might know, GitHub recently launched GitHub Actions where people can automate workflows like build, test, deploy code from GitHub.\nI have started reading docs a little bit, I have to admit, setting up workflows on GitHub Actions is not that hard. I can directly start creating workflow from available workflow templates in the \u0026ldquo;Actions\u0026rdquo; tab. Then I saw the workflow template for \u0026ldquo;Jekyll Site CI/CD\u0026rdquo;, builds Jekyll site. I got some feeling that I automate my workflow of building and deploying my blog (which currently you are reading) on GitHub Pages. So, Let\u0026rsquo;s see how did I setup CI/CD\nBut first let me explain how my blog site works and then manual steps every time I do to publish a blog.\nGitHub Pages This blog site is powered by GitHub Pages which you can publish static html site right from GitHub repository (For example my repo here). All you have to do is to create a repo name like \u0026lt;YourGitHubUsername\u0026gt;.github.io and drop static html pages in master branch. That\u0026rsquo;s it, GitHub does the magic, serves your website.\nFor this, I\u0026rsquo;m maintaining 2 branches, one for my markdown source files in source branch and another for static html site in master branch\nJekyll Everything\u0026rsquo;s good so far, but we know that we are too lazy to write html pages. So, that\u0026rsquo;s where this tool \u0026ldquo;Jekyll\u0026rdquo; comes into picture, converts markdown files to static html websites. Once you jekyll build, it will build a static website in the _site directory. For local testing you can run jekyll serve to see how site looks.(Checkout my other post to know how to install jekyll)\nMy Manual Workflow Write blog post in markdown files which I keep in source branch (Obviously I can not automate this step :-P) Run jekyll build to build static website Copy static website content from _site to master branch Push master branch changes to repo to publish website Push source branch changes to repo to store/version tracking GitHub Actions Below is the jekyll.yml to automate my workflow\nLet\u0026rsquo;s go thought the jekyll.yml line by line very briefly\nLine No. Description 3 Event subscription; I want to trigger the workflow only when there is any push in \u0026ldquo;source\u0026rdquo; branch 11 I want to run this build procedure on ubuntu box(GitHub action supports other box as well like windows, mac, etc) 16 In order to build, first I have to clone the repo, for this, there is ready made action called \u0026ldquo;actions/checkout@v2\u0026rdquo; which checkouts my repo with \u0026ldquo;source\u0026rdquo; branch 21 Since I can\u0026rsquo;t expect GitHub servers to have \u0026ldquo;jekyll\u0026rdquo; installed, I built my own docker image for jekyll with dependency gems to build a website. (You can find other jekyll docker image, I\u0026rsquo;m using older version of jekyll, that\u0026rsquo;s why I built my own) 28 I want to push static website to \u0026ldquo;master\u0026rdquo; branch, so I have to checkout \u0026ldquo;master\u0026rdquo; branch as well 33 Copy \u0026ldquo;_site\u0026rdquo; content to master branch 37 Normal shell commands, git add and git commit 44 Finally push changes to \u0026ldquo;master\u0026rdquo; to publish website with help of using ready made action \u0026ldquo;ad-m/GitHub-push-action@master\u0026rdquo; Now, all I have to do is drop jekyll.yml in the .github/workflows/ directory to GitHub to pick up my workflow. Below is the picture showing the pipeline for my website deployment.\n","permalink":"https://veerendra2.github.io/posts/ci-cd-github-pages-with-github-actions/","summary":"Looks like my blog posts are like Sherlock TV Show episodes, posting once in a while..anyways I\u0026rsquo;m back now. As you might know, GitHub recently launched GitHub Actions where people can automate workflows like build, test, deploy code from GitHub.\nI have started reading docs a little bit, I have to admit, setting up workflows on GitHub Actions is not that hard. I can directly start creating workflow from available workflow templates in the \u0026ldquo;Actions\u0026rdquo; tab.","title":"CI/CD for GitHub Pages with GitHub Actions"},{"content":"Hallo alle zusammen, after a long time I\u0026rsquo;m writing this blog and I come with an interesting and long post\nI know what you are thinking, I steal Kelsey Hightower\u0026rsquo;s Kubernetes The Hard Way tutorial, but hey!, I did some research and try to fit K8s cluster(Multi-Master!) in a laptop with Docker as \u0026lsquo;CRI\u0026rsquo; and Flannel as \u0026lsquo;CNI\u0026rsquo;.\nThis blog post follows Kelsey Hightower\u0026rsquo;s Kubernetes The Hard Way, I highly recommend go through his repo. I\u0026rsquo;m writing this blog post to keep it as reference for me and share with other people whoever want to try it. So, feel free to correct me if there are any mistakes and ping me for any queries. This series is divided into 3 parts and all configuration/scripts are available in my github repo. Well that has been said, let\u0026rsquo;s start building the cluster.\nBelow is my laptop configuration. Make sure you have enough resources in your laptop.(or depends on resources, you can reduce nodes in the cluster, etc.)\nLaptop Acer Predator Helios 200 CPU Intel Core i5 8th Gen RAM 8 GB Host OS Ubuntu 18.04 Hostname ghost First let\u0026rsquo;s talk about the cluster in Kubernetes The Hard Way which has 3 controller nodes, 3 worker nodes and a load balancer on GCP. I want to deploy a cluster with multiple masters, but I was afraid it is too much for my laptop. So, I reduced it to 2 controller nodes, 2 worker nodes (or VMs in my case) and replaced GCP load balancer with nginx docker container as a load balancer, the clusters look like below.\n1. Prerequisites Installation of packages *NOTE: The following components will be installed on host machine(laptop)\nInstall KVM hypervisor. $ sudo apt-get install qemu-kvm quem-system \\ libvirt-bin bridge-utils \\ virt-manager -y Install Docker, because we want to run nginx load balancer container on host Install cfssl and cfssljson binaries $ wget -q --show-progress --https-only --timestamping \\ https://pkg.cfssl.org/R1.2/cfssl_linux-amd64 \\ https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64 $ chmod +x cfssl_linux-amd64 cfssljson_linux-amd64 $ sudo mv cfssl_linux-amd64 /usr/local/bin/cfssl $ sudo mv cfssljson_linux-amd64 /usr/local/bin/cfssljson $ wget https://storage.googleapis.com/kubernetes-release/release/v1.12.0/bin/linux/amd64/kubectl $ chmod +x kubectl $ sudo mv kubectl /usr/local/bin/ Subnets In official \u0026ldquo;Kubernetes The Hard Way\u0026rdquo;, cluster network configuration done via gcloud and obviously we are not going to use it. We have to choose subnets manually for our cluster nodes,CIDR for pods and K8s services. So, here is what I come with\nNo. Name Subnet 1 Cluster Nodes 10.200.1.0/24 2 POD CIDR(cluster-cidr) 10.100.0.0/16 3 Service(service-cluster-ip) 10.32.0.0/24 Linux Bridge \u0026amp; NAT As you can see in the above diagram, we are going to use a linux bridge to connect our VMs and nginx docker container. Also we need to do NATing for our VMs in order to access the Internet.\n$ EXTERNAL_IFACE=\u0026#34;wlan0\u0026#34; ## Enable ip forwarding $ sudo sysctl net.ipv4.conf.all.forwarding=1 ## Create br0 bridge $ sudo ip link add name br0 type bridge $ sudo ip link set dev br0 up $ sudo ip addr add 10.200.1.1/24 dev br0 ## iptables NAT configuration $ sudo iptables -t nat -A POSTROUTING -o $EXTERNAL_IFACE -j MASQUERADE $ sudo iptables -A FORWARD -i $EXTERNAL_IFACE -o br0 -m state --state RELATED,ESTABLISHED -j ACCEPT $ sudo iptables -A FORWARD -i br0 -o $EXTERNAL_IFACE -j ACCEPT ## Bridge config. Read more @ https://tinyurl.com/yan5jnd4 $ sudo sysctl -w net.bridge.bridge-nf-call-arptables=0 $ sudo sysctl -w net.bridge.bridge-nf-call-ip6tables=0 $ sudo sysctl -w net.bridge.bridge-nf-call-iptables=0 In order to launch docker container(nginx load balancer container) on different linux bridge(other than default docker0), we need to create a docker network and specify that network while launching the container. Below command creates docker network with br0 as bridge\n$ docker network create --driver=bridge \\ --ip-range=10.200.1.0/24 \\ --subnet=10.200.1.0/24 -o \u0026#34;com.docker.network.bridge.name=br0\u0026#34; br0 Create workspace directory We can save all configuration and generate certificates in this directory\n$ mkdir ~/kubernetes-the-hard-way $ cd ~/kubernetes-the-hard-way 2. Provisioning Compute Resources Specify cluster info(hostname, IP and user to login) in controllers.txt and workers.txt files respectively like in below. In the same way add those VM IPs in /etc/hosts file like below. These files are useful to automate things like copy files to nodes or generating certificates for these nodes, etc. You will see in a moment.\n$ cd ~/kubernetes-the-hard-way $ cat controllers.txt m1 10.200.1.10 veeru m2 10.200.1.11 veeru $ cat workers.txt n2 10.200.1.13 veeru n2 10.200.1.14 veeru $ cat nginx_proxy.txt proxy 10.200.1.15 $ cat /etc/hosts 127.0.0.1 localhost 127.0.1.1 ghost 10.200.1.10 m1 10.200.1.11 m2 10.200.1.12 n1 10.200.1.13 n2 10.200.1.15 nginx Below are the IPs, hostname and username for the nodes that I choose\nNode Role Node Hostname Node IP Node Login Username Controller m1 10.200.1.10 veeru Controller m2 10.200.1.11 veeru Worker n1 10.200.1.13 veeru Worker n2 10.200.1.14 veeru Load Balancer(nginx Container) proxy 10.200.1.15 N/A Download Ubuntu 18.04 server .iso from https://www.ubuntu.com/ In previous section, we installed kvm hypervisor and now lets spin up 4 VMs and specify bridge name under network section like in below screenshot.(I used \u0026ldquo;Virtual Machine Manager\u0026rdquo; GUI to launch VMs) *I\u0026rsquo;m not covering OS installation in VM. You can easily find it on the Internet.\n*NOTE: While installing OS, please select static IP and specify IPs according to their node names\n*TIP: Install OS in VM and clone VM 3 time\nOnce the OS installation is completed, check the connectivity between the host-VM and VM-VM and you should be able to ssh both host-to-VM and VM-to-VM. For convenience, you can copy ssh keys, so that you don\u0026rsquo;t have to enter a password every time.\n$ ssh-keygen $ ssh-copy-id guest-username@guest-ip 3. Provisioning a CA and Generating TLS Certificates It is a good practice to set up encrypted communication between the components of K8s. In this section we will create public key certificates and private keys for below components using CloudFlare\u0026rsquo;s PKI toolkit as we downloaded earlier.(Know more about PKI)\nadmin user kubelet kube-controller-manager kube-proxy kube-scheduler kube-api But first, we have to create Certificate Authority(CA) which e-signatures the certificates that we are going to generate.\n$ cd ~/kubernetes-the-hard-way $ wget -q https://raw.githubusercontent.com/veerendra2/k8s-the-hard-way-blog/master/certificate_configs/ca-config.json $ wget -q https://raw.githubusercontent.com/veerendra2/k8s-the-hard-way-blog/master/certificate_configs/ca-csr.json ## Generate CA $ cfssl gencert -initca ca-csr.json | cfssljson -bare ca $ ls ca-key.pem ca.pem Admin User Client Certificate $ cd ~/kubernetes-the-hard-way $ wget -q https://raw.githubusercontent.com/veerendra2/k8s-the-hard-way-blog/master/certificate_configs/admin-csr.json $ cfssl gencert \\ -ca=ca.pem \\ -ca-key=ca-key.pem \\ -config=ca-config.json \\ -profile=kubernetes \\ admin-csr.json | cfssljson -bare admin $ ls admin-key.pem admin.pem Kubelet Client Certificates As docs says\nK8s uses node authorization which is a special-purpose authorization mode that specifically authorizes API requests made by kubelets\nIn order to be authorized by the Node Authorizer, Kubelets must use a credential that identifies them as being in the system:nodes group, with a username of system:node:\u0026lt;nodeName\u0026gt;. Let\u0026rsquo;s create a certificate and private key for each worker nodes (In my case n1 and n2)\n$ cd ~/kubernetes-the-hard-way IFS=$\u0026#39;\\n\u0026#39; for line in `cat workers.txt`; do instance=`echo $line | awk \u0026#39;{print $1}\u0026#39;` INTERNAL_IP=`echo $line | awk \u0026#39;{print $2}\u0026#39;` cat \u0026gt; ${instance}-csr.json \u0026lt;\u0026lt;EOF { \u0026#34;CN\u0026#34;: \u0026#34;system:node:${instance}\u0026#34;, \u0026#34;key\u0026#34;: { \u0026#34;algo\u0026#34;: \u0026#34;rsa\u0026#34;, \u0026#34;size\u0026#34;: 2048 }, \u0026#34;names\u0026#34;: [ { \u0026#34;C\u0026#34;: \u0026#34;Westeros\u0026#34;, \u0026#34;L\u0026#34;: \u0026#34;The North\u0026#34;, \u0026#34;O\u0026#34;: \u0026#34;system:nodes\u0026#34;, \u0026#34;OU\u0026#34;: \u0026#34;Kubernetes The Hard Way\u0026#34;, \u0026#34;ST\u0026#34;: \u0026#34;Winterfell\u0026#34; } ] } EOF cfssl gencert \\ -ca=ca.pem \\ -ca-key=ca-key.pem \\ -config=ca-config.json \\ -hostname=${instance},${INTERNAL_IP} \\ -profile=kubernetes \\ ${instance}-csr.json | cfssljson -bare ${instance} done $ ls n1-key.pem n1.pem n2-key.pem n2.pem Controller Manager Client Certificate $ cd ~/kubernetes-the-hard-way $ wget -q https://raw.githubusercontent.com/veerendra2/k8s-the-hard-way-blog/master/certificate_configs/kube-controller-manager-csr.json # Generate Certificate $ cfssl gencert \\ -ca=ca.pem \\ -ca-key=ca-key.pem \\ -config=ca-config.json \\ -profile=kubernetes \\ kube-controller-manager-csr.json | cfssljson -bare kube-controller-manager $ ls kube-controller-manager-key.pem kube-controller-manager.pem Kube Proxy Client Certificate $ cd ~/kubernetes-the-hard-way $ wget -q https://raw.githubusercontent.com/veerendra2/k8s-the-hard-way-blog/master/certificate_configs/kube-proxy-csr.json # Generate Certificate $ cfssl gencert \\ -ca=ca.pem \\ -ca-key=ca-key.pem \\ -config=ca-config.json \\ -profile=kubernetes \\ kube-proxy-csr.json | cfssljson -bare kube-proxy $ ls kube-proxy-key.pem kube-proxy.pem Scheduler Client Certificate $ cd ~/kubernetes-the-hard-way $ wget -q https://raw.githubusercontent.com/veerendra2/k8s-the-hard-way-blog/master/certificate_configs/kube-scheduler-csr.json # Generate Certificate $ cfssl gencert \\ -ca=ca.pem \\ -ca-key=ca-key.pem \\ -config=ca-config.json \\ -profile=kubernetes \\ kube-scheduler-csr.json | cfssljson -bare kube-scheduler $ ls kube-scheduler-key.pem kube-scheduler.pem Kubernetes API Server Certificate kube-api server certificate\u0026rsquo;s hostname should include following things\nAll controller\u0026rsquo;s hostname All controller\u0026rsquo;s IP Load balancer\u0026rsquo;s hostname Load balancer\u0026rsquo;s IP Kubernetes\u0026rsquo;s service(Both \u0026lsquo;service name\u0026rsquo; and IP which are 10.32.0.1 and kubernetes.default) localhost $ cd ~/kubernetes-the-hard-way ## CERT_HOSTNAME=10.32.0.1,\u0026lt;master node 1 Private IP\u0026gt;,\u0026lt;master node 1 hostname\u0026gt;,\u0026lt;master node 2 Private IP\u0026gt;,\u0026lt;master node 2 hostname\u0026gt;,\u0026lt;API load balancer Private IP\u0026gt;,\u0026lt;API load balancer hostname\u0026gt;,127.0.0.1,localhost,kubernetes.default $ CERT_HOSTNAME=10.32.0.1,m1,10.200.1.10,m2,10.200.1.11,proxy,10.200.1.15,127.0.0.1,localhost,kubernetes.default $ wget -q https://raw.githubusercontent.com/veerendra2/k8s-the-hard-way-blog/master/certificate_configs/kubernetes-csr.json $ cfssl gencert \\ -ca=ca.pem \\ -ca-key=ca-key.pem \\ -config=ca-config.json \\ -hostname=${CERT_HOSTNAME} \\ -profile=kubernetes \\ kubernetes-csr.json | cfssljson -bare kubernetes $ ls Service Account Key Pair Service account key pair certificate is used to sign service account tokens\n$ cd ~/kubernetes-the-hard-way $ wget -q https://raw.githubusercontent.com/veerendra2/k8s-the-hard-way-blog/master/certificate_configs/service-account-csr.json $ cfssl gencert \\ -ca=ca.pem \\ -ca-key=ca-key.pem \\ -config=ca-config.json \\ -profile=kubernetes \\ service-account-csr.json | cfssljson -bare service-account $ ls service-account-key.pem service-account.pem Copy Certificates to Nodes $ cd ~/kubernetes-the-hard-way # Minion $ IFS=$\u0026#39;\\n\u0026#39; $ for line in `cat workers.txt`; do instance=`echo $line | awk \u0026#39;{print $1}\u0026#39;` user=`echo $line | awk \u0026#39;{print $3}\u0026#39;` rsync -zvhe ssh ca.pem ${instance}-key.pem ${instance}.pem ${user}@${instance}:~/ done # Master $ IFS=$\u0026#39;\\n\u0026#39; $ for instance in `cat controllers.txt`; do instance=`echo $line | awk \u0026#39;{print $1}\u0026#39;` user=`echo $line | awk \u0026#39;{print $3}\u0026#39;` rsync -zvhe ssh ca.pem ca-key.pem kubernetes-key.pem kubernetes.pem \\ service-account-key.pem service-account.pem ${user}@${instance}:~/ done 4. Generating kubeconfig Files for Authentication kubeconfig are used for authentication between the kubernetes components and users-to-kubernetes. kubeconfig consists of mainly 3 things\nNo. Entity Description 1 Cluster api-server\u0026rsquo;s IP and its certificate which encodes in base64 2 Users User related info like who are authenticating ,their certificate and key or service account token 3 Context Holds Cluster\u0026rsquo;s and User\u0026rsquo;s reference. If you have multiple clusters and users, this context becomes handy In this section, we are going to generate kubeconfig for below components\nGenerating kubelet kubeconfig The user in kubeconfig should be system:node:\u0026lt;Worker_name\u0026gt; which should match the Kubelet hostname that we specified while generating the kubelet client certificate. This will ensure Kubelets are properly authorized by the Kubernetes Node Authorizer.\n$ cd ~/kubernetes-the-hard-way $ KUBERNETES_PUBLIC_ADDRESS=`cat nginx_proxy.txt | awk \u0026#39;{print $2}\u0026#39;` $ IFS=$\u0026#39;\\n\u0026#39; $ for instance in `cat workers.txt`; do instance=`echo $line | awk \u0026#39;{print $1}\u0026#39;` kubectl config set-cluster kubernetes-the-hard-way \\ --certificate-authority=ca.pem \\ --embed-certs=true \\ --server=https://${KUBERNETES_PUBLIC_ADDRESS}:6443 \\ --kubeconfig=${instance}.kubeconfig kubectl config set-credentials system:node:${instance} \\ --client-certificate=${instance}.pem \\ --client-key=${instance}-key.pem \\ --embed-certs=true \\ --kubeconfig=${instance}.kubeconfig kubectl config set-context default \\ --cluster=kubernetes-the-hard-way \\ --user=system:node:${instance} \\ --kubeconfig=${instance}.kubeconfig kubectl config use-context default --kubeconfig=${instance}.kubeconfig done $ ls n1.kubeconfig n2.kubeconfig Generate kube-proxy kubeconfig $ cd ~/kubernetes-the-hard-way $ KUBERNETES_PUBLIC_ADDRESS=`cat nginx_proxy.txt | awk \u0026#39;{print $2}\u0026#39;` $ { kubectl config set-cluster kubernetes-the-hard-way \\ --certificate-authority=ca.pem \\ --embed-certs=true \\ --server=https://${KUBERNETES_PUBLIC_ADDRESS}:6443 \\ --kubeconfig=kube-proxy.kubeconfig kubectl config set-credentials system:kube-proxy \\ --client-certificate=kube-proxy.pem \\ --client-key=kube-proxy-key.pem \\ --embed-certs=true \\ --kubeconfig=kube-proxy.kubeconfig kubectl config set-context default \\ --cluster=kubernetes-the-hard-way \\ --user=system:kube-proxy \\ --kubeconfig=kube-proxy.kubeconfig kubectl config use-context default --kubeconfig=kube-proxy.kubeconfig } $ ls kube-proxy.kubeconfig Generate kube-controller-manager kubeconfig $ cd ~/kubernetes-the-hard-way { kubectl config set-cluster kubernetes-the-hard-way \\ --certificate-authority=ca.pem \\ --embed-certs=true \\ --server=https://127.0.0.1:6443 \\ --kubeconfig=kube-controller-manager.kubeconfig kubectl config set-credentials system:kube-controller-manager \\ --client-certificate=kube-controller-manager.pem \\ --client-key=kube-controller-manager-key.pem \\ --embed-certs=true \\ --kubeconfig=kube-controller-manager.kubeconfig kubectl config set-context default \\ --cluster=kubernetes-the-hard-way \\ --user=system:kube-controller-manager \\ --kubeconfig=kube-controller-manager.kubeconfig kubectl config use-context default --kubeconfig=kube-controller-manager.kubeconfig } $ ls kube-controller-manager.kubeconfig Generate kube-scheduler kubeconfig $ cd ~/kubernetes-the-hard-way $ { kubectl config set-cluster kubernetes-the-hard-way \\ --certificate-authority=ca.pem \\ --embed-certs=true \\ --server=https://127.0.0.1:6443 \\ --kubeconfig=kube-scheduler.kubeconfig kubectl config set-credentials system:kube-scheduler \\ --client-certificate=kube-scheduler.pem \\ --client-key=kube-scheduler-key.pem \\ --embed-certs=true \\ --kubeconfig=kube-scheduler.kubeconfig kubectl config set-context default \\ --cluster=kubernetes-the-hard-way \\ --user=system:kube-scheduler \\ --kubeconfig=kube-scheduler.kubeconfig kubectl config use-context default --kubeconfig=kube-scheduler.kubeconfig } $ ls kube-scheduler.kubeconfig Generate admin kubeconfig $ cd ~/kubernetes-the-hard-way $ { kubectl config set-cluster kubernetes-the-hard-way \\ --certificate-authority=ca.pem \\ --embed-certs=true \\ --server=https://127.0.0.1:6443 \\ --kubeconfig=admin.kubeconfig kubectl config set-credentials admin \\ --client-certificate=admin.pem \\ --client-key=admin-key.pem \\ --embed-certs=true \\ --kubeconfig=admin.kubeconfig kubectl config set-context default \\ --cluster=kubernetes-the-hard-way \\ --user=admin \\ --kubeconfig=admin.kubeconfig kubectl config use-context default --kubeconfig=admin.kubeconfig } $ ls admin.kubeconfig Copy kubeconfig files to nodes $ cd ~/kubernetes-the-hard-way $ IFS=$\u0026#39;\\n\u0026#39; $ for line in `cat workers.txt`; do instance=`echo $line | awk \u0026#39;{print $1}\u0026#39;` user=`echo $line | awk \u0026#39;{print $3}\u0026#39;` rsync -zvhe ssh ${instance}.kubeconfig kube-proxy.kubeconfig ${user}@${instance}:~/ done $ for instance in `cat controllers.txt`; do instance=`echo $line | awk \u0026#39;{print $1}\u0026#39;` user=`echo $line | awk \u0026#39;{print $3}\u0026#39;` rsync -zvhe ssh admin.kubeconfig kube-controller-manager.kubeconfig kube-scheduler.kubeconfig ${user}@${instance}:~/ done 5. Generating the Data Encryption Config and Key Kubernetes stores different types of data including cluster state, application configurations, and secrets. Kubernetes supports the ability to encrypt cluster data at rest.In this section we will generate an encryption key and an encryption config suitable for encrypting Kubernetes Secrets.\nThe Encrypted Key ENCRYPTION_KEY=$(head -c 32 /dev/urandom | base64) The Encryption Config File cat \u0026gt; encryption-config.yaml \u0026lt;\u0026lt;EOF kind: EncryptionConfig apiVersion: v1 resources: - resources: - secrets providers: - aescbc: keys: - name: key1 secret: ${ENCRYPTION_KEY} - identity: {} EOF Copy to Controller Nodes $ IFS=$\u0026#39;\\n\u0026#39; $ for instance in `cat controller.txt`; do instance=`echo $line | awk \u0026#39;{print $1}\u0026#39;` user=`echo $line | awk \u0026#39;{print $3}\u0026#39;` rsync -zvhe ssh encryption-config.yaml ${user}@${instance}:~/ done Till now we have done following things\nProvisioned compute resources Generated certificates Generated kubeconfig files Copied certificate files and kubeconfigs to nodes In the next post, we will bootstrap controller nodes\n","permalink":"https://veerendra2.github.io/posts/kubernetes-the-hard-way-1/","summary":"Hallo alle zusammen, after a long time I\u0026rsquo;m writing this blog and I come with an interesting and long post\nI know what you are thinking, I steal Kelsey Hightower\u0026rsquo;s Kubernetes The Hard Way tutorial, but hey!, I did some research and try to fit K8s cluster(Multi-Master!) in a laptop with Docker as \u0026lsquo;CRI\u0026rsquo; and Flannel as \u0026lsquo;CNI\u0026rsquo;.\nThis blog post follows Kelsey Hightower\u0026rsquo;s Kubernetes The Hard Way, I highly recommend go through his repo.","title":"Kubernetes-The Hard Way With Docker \u0026 Flannel (Part 1)"},{"content":"Welcome back to \u0026ldquo;Kubernetes-The Hard Way With Docker \u0026amp; Flannel\u0026rdquo; series part 2. In previous post we have provisioned compute resources, generated certificates and kubeconfig files. In this post, we will install and configure controller nodes\n6. Bootstrapping the etcd Cluster etcd is a consistent and highly-available key value storage DB. Kubernetes stores all cluster data in etcd via api-server. In this section we will install and configure etcd on all controller nodes.\n*NOTE: The below commands must run on all controller nodes\n*TIP: You can use tumx to run command on multiple nodes at same time\n## On controller nodes $ wget -q --show-progress --https-only --timestamping \\ \u0026#34;https://github.com/coreos/etcd/releases/download/v3.3.9/etcd-v3.3.9-linux-amd64.tar.gz\u0026#34; $ tar -xvf etcd-v3.3.9-linux-amd64.tar.gz $ sudo mv etcd-v3.3.9-linux-amd64/etcd* /usr/local/bin/ $ sudo mkdir -p /etc/etcd /var/lib/etcd $ sudo cp ca.pem kubernetes-key.pem kubernetes.pem /etc/etcd/ Set up the following environment variables which are usefull generate etcd systemd unit file\n## On controller nodes $ ETCD_NAME=`hostname` $ INTERNAL_IP=`hostname -i` # IP of the current node #INITIAL_CLUSTER=\u0026lt;controller 1 hostname\u0026gt;=https://\u0026lt;controller 1 private ip\u0026gt;:2380,\u0026lt;controller 2 hostname\u0026gt;=https://\u0026lt;controller 2 private ip\u0026gt;:2380 $ INITIAL_CLUSTER=m1=https://10.200.1.10:2380,m2=https://10.200.1.11:2380 Create systemd unit file\n## On controller nodes $ cat \u0026lt;\u0026lt; EOF | sudo tee /etc/systemd/system/etcd.service [Unit] Description=etcd Documentation=https://github.com/coreos [Service] ExecStart=/usr/local/bin/etcd \\\\ --name ${ETCD_NAME} \\\\ --cert-file=/etc/etcd/kubernetes.pem \\\\ --key-file=/etc/etcd/kubernetes-key.pem \\\\ --peer-cert-file=/etc/etcd/kubernetes.pem \\\\ --peer-key-file=/etc/etcd/kubernetes-key.pem \\\\ --trusted-ca-file=/etc/etcd/ca.pem \\\\ --peer-trusted-ca-file=/etc/etcd/ca.pem \\\\ --peer-client-cert-auth \\\\ --client-cert-auth \\\\ --initial-advertise-peer-urls https://${INTERNAL_IP}:2380 \\\\ --listen-peer-urls https://${INTERNAL_IP}:2380 \\\\ --listen-client-urls https://${INTERNAL_IP}:2379,https://127.0.0.1:2379 \\\\ --advertise-client-urls https://${INTERNAL_IP}:2379 \\\\ --initial-cluster-token etcd-cluster-0 \\\\ --initial-cluster ${INITIAL_CLUSTER} \\\\ --initial-cluster-state new \\\\ --data-dir=/var/lib/etcd Restart=on-failure RestartSec=5 [Install] WantedBy=multi-user.target EOF Start the etcd service\n## On controller nodes $ { sudo systemctl daemon-reload sudo systemctl enable etcd sudo systemctl start etcd } Once etcd installation and configuration done in all controller nodes, verify that etcd cluster is working properly\n## On controller nodes $ sudo ETCDCTL_API=3 etcdctl member list \\ --endpoints=https://127.0.0.1:2379 \\ --cacert=/etc/etcd/ca.pem \\ --cert=/etc/etcd/kubernetes.pem \\ --key=/etc/etcd/kubernetes-key.pem You should see output like below\n7. Bootstrapping the Kubernetes Control Plane The control plane binaries are\nkube-apiserver kube-controller-manager kube-scheduler Download control plane binaries\n*NOTE: The below commands must run on all controller nodes\n## On controller nodes $ sudo mkdir -p /etc/kubernetes/config $ KUBERNETES_VERSION=v1.10.13 $ wget -q --show-progress --https-only --timestamping \\ \u0026#34;https://dl.k8s.io/${KUBERNETES_VERSION}/bin/linux/amd64/kube-apiserver\u0026#34; \\ \u0026#34;https://dl.k8s.io/${KUBERNETES_VERSION}/bin/linux/amd64/kube-controller-manager\u0026#34; \\ \u0026#34;https://dl.k8s.io/${KUBERNETES_VERSION}/bin/linux/amd64/kube-scheduler\u0026#34; \\ \u0026#34;https://dl.k8s.io/${KUBERNETES_VERSION}/bin/linux/amd64/kubectl\u0026#34; *TIP: You can get version number from kubernetes releases page\nMove the binaries to /usr/local/bin/\n## On controller nodes $ chmod +x kube-apiserver kube-controller-manager kube-scheduler kubectl $ sudo mv kube-apiserver kube-controller-manager kube-scheduler kubectl /usr/local/bin/ Kubernetes API Server Configuration Move certificates to kubernetes directory\n## On controller nodes $ sudo mkdir -p /var/lib/kubernetes/ $ sudo mv ca.pem ca-key.pem kubernetes-key.pem kubernetes.pem \\ service-account-key.pem service-account.pem \\ encryption-config.yaml /var/lib/kubernetes/ Create a kube-api server systemd unit file.\n## On controller nodes $ CONTROLLER0_IP=10.200.1.10 $ CONTROLLER1_IP=10.200.1.11 $ INTERNAL_IP=`hostname -i` # Current node\u0026#39;s IP $ cat \u0026lt;\u0026lt; EOF | sudo tee /etc/systemd/system/kube-apiserver.service [Unit] Description=Kubernetes API Server Documentation=https://github.com/kubernetes/kubernetes [Service] ExecStart=/usr/local/bin/kube-apiserver \\\\ --advertise-address=${INTERNAL_IP} \\\\ --allow-privileged=true \\\\ --apiserver-count=3 \\\\ --audit-log-maxage=30 \\\\ --audit-log-maxbackup=3 \\\\ --audit-log-maxsize=100 \\\\ --audit-log-path=/var/log/audit.log \\\\ --authorization-mode=Node,RBAC \\\\ --bind-address=0.0.0.0 \\\\ --client-ca-file=/var/lib/kubernetes/ca.pem \\\\ --enable-admission-plugins=Initializers,NamespaceLifecycle,NodeRestriction,LimitRanger,ServiceAccount,DefaultStorageClass,ResourceQuota \\\\ --enable-swagger-ui=true \\\\ --etcd-cafile=/var/lib/kubernetes/ca.pem \\\\ --etcd-certfile=/var/lib/kubernetes/kubernetes.pem \\\\ --etcd-keyfile=/var/lib/kubernetes/kubernetes-key.pem \\\\ --etcd-servers=https://$CONTROLLER0_IP:2379,https://$CONTROLLER1_IP:2379 \\\\ --event-ttl=1h \\\\ --experimental-encryption-provider-config=/var/lib/kubernetes/encryption-config.yaml \\\\ --kubelet-certificate-authority=/var/lib/kubernetes/ca.pem \\\\ --kubelet-client-certificate=/var/lib/kubernetes/kubernetes.pem \\\\ --kubelet-client-key=/var/lib/kubernetes/kubernetes-key.pem \\\\ --kubelet-https=true \\\\ --runtime-config=api/all \\\\ --service-account-key-file=/var/lib/kubernetes/service-account.pem \\\\ --service-cluster-ip-range=10.32.0.0/24 \\\\ --service-node-port-range=30000-32767 \\\\ --tls-cert-file=/var/lib/kubernetes/kubernetes.pem \\\\ --tls-private-key-file=/var/lib/kubernetes/kubernetes-key.pem \\\\ --v=2 \\\\ --kubelet-preferred-address-types=InternalIP,InternalDNS,Hostname,ExternalIP,ExternalDNS Restart=on-failure RestartSec=5 [Install] WantedBy=multi-user.target EOF Kubernetes Controller Manager Configuration Move kubeconfig files to kubernetes directory\n## On controller nodes $ sudo mv kube-controller-manager.kubeconfig /var/lib/kubernetes/ Create kube-controller-manager systemd unit file\n## On controller nodes $ cat \u0026lt;\u0026lt;EOF | sudo tee /etc/systemd/system/kube-controller-manager.service [Unit] Description=Kubernetes Controller Manager Documentation=https://github.com/kubernetes/kubernetes [Service] ExecStart=/usr/local/bin/kube-controller-manager \\\\ --address=0.0.0.0 \\\\ --cluster-cidr=10.200.0.0/16 \\\\ --cluster-name=kubernetes \\\\ --cluster-signing-cert-file=/var/lib/kubernetes/ca.pem \\\\ --cluster-signing-key-file=/var/lib/kubernetes/ca-key.pem \\\\ --kubeconfig=/var/lib/kubernetes/kube-controller-manager.kubeconfig \\\\ --leader-elect=true \\\\ --root-ca-file=/var/lib/kubernetes/ca.pem \\\\ --service-account-private-key-file=/var/lib/kubernetes/service-account-key.pem \\\\ --service-cluster-ip-range=10.32.0.0/24 \\\\ --use-service-account-credentials=true \\\\ --v=2 Restart=on-failure RestartSec=5 [Install] WantedBy=multi-user.target EOF Kubernetes Scheduler Configuration Move kube-scheduler kubeconfig to kubernetes directory\n# On controller nodes $ sudo mv kube-scheduler.kubeconfig /var/lib/kubernetes/ Create kube-scheduler configuration file\n## On controller nodes $ cat \u0026lt;\u0026lt;EOF | sudo tee /etc/kubernetes/config/kube-scheduler.yaml apiVersion: componentconfig/v1alpha1 kind: KubeSchedulerConfiguration clientConnection: kubeconfig: \u0026#34;/var/lib/kubernetes/kube-scheduler.kubeconfig\u0026#34; leaderElection: leaderElect: true EOF {% endhighlight %} Create kube-scheduler systemd unit file {% highlight shell %} # On controller nodes $ cat \u0026lt;\u0026lt;EOF | sudo tee /etc/systemd/system/kube-scheduler.service [Unit] Description=Kubernetes Scheduler Documentation=https://github.com/kubernetes/kubernetes [Service] ExecStart=/usr/local/bin/kube-scheduler \\\\ --config=/etc/kubernetes/config/kube-scheduler.yaml \\\\ --v=2 Restart=on-failure RestartSec=5 [Install] WantedBy=multi-user.target EOF Start the controller services ## On controller nodes $ sudo systemctl daemon-reload $ sudo systemctl enable kube-apiserver kube-controller-manager kube-scheduler $ sudo systemctl start kube-apiserver kube-controller-manager kube-scheduler Enable HTTP Health Checks In the original \u0026ldquo;Kubernetes The Hard Way\u0026rdquo;, Kelsey used GCP load balancer to load balance the requests among controllers. Since it is difficult to set up HTTPS health checks on GCP network load balancer and kube-apiserver supports only HTTPS health checks. He created HTTP nginx proxy for kube-api server, GCP network load balancer performs health check via HTTP nginx proxy. But in our case, we can skip this step since we are not using GCP network load balancer\nVerification Check the components status using below commands.\n## On controller nodes $ kubectl get componentstatuses --kubeconfig admin.kubeconfig Run above command on all controller nodes and verify statuses which should like below\nRBAC for Kubelet Authorization In this section we will configure RBAC permissions to allow the kube-api server to access the Kubelet API on each worker node. Access to the Kubelet API is required for retrieving metrics, logs, and executing commands in pods.\nCreate the system:kube-apiserver-to-kubelet ClusterRole with permissions to access the Kubelet.\n## On controller nodes $ cat \u0026lt;\u0026lt;EOF | kubectl apply --kubeconfig admin.kubeconfig -f - apiVersion: rbac.authorization.k8s.io/v1beta1 kind: ClusterRole metadata: annotations: rbac.authorization.kubernetes.io/autoupdate: \u0026#34;true\u0026#34; labels: kubernetes.io/bootstrapping: rbac-defaults name: system:kube-apiserver-to-kubelet rules: - apiGroups: - \u0026#34;\u0026#34; resources: - nodes/proxy - nodes/stats - nodes/log - nodes/spec - nodes/metrics verbs: - \u0026#34;*\u0026#34; EOF The kube-api server authenticates to the Kubelet as the \u0026ldquo;kubernetes\u0026rdquo; user using the client certificate as defined by the --kubelet-client-certificate flag which has been defined in the kube-apiserver systemd unit file above.\nBind the system:kube-apiserver-to-kubelet ClusterRole to the kubernetes user:\n## On controller nodes $ cat \u0026lt;\u0026lt;EOF | kubectl apply --kubeconfig admin.kubeconfig -f - apiVersion: rbac.authorization.k8s.io/v1beta1 kind: ClusterRoleBinding metadata: name: system:kube-apiserver namespace: \u0026#34;\u0026#34; roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: system:kube-apiserver-to-kubelet subjects: - apiGroup: rbac.authorization.k8s.io kind: User name: kubernetes EOF The Kubernetes Frontend Load Balancer As I said earlier, we are not going using GCP load network load balancer, but we are going using nginx docker container on host(Laptop) to load balance the requests.\nIn this section, we will build nginx docker image with appropriate configuration to load balance requests among controller nodes(m1 and m2)\nnginx configuration Specify controllers IPs with kube-api server\u0026rsquo;s port in nginx configuration like below\n## On host cd ~/kubernetes-the-hard-way $ cat \u0026lt;\u0026lt;EOF | tee kubernetes.conf stream { upstream kubernetes { server 10.200.1.10:6443; server 10.200.1.11:6443; } server { listen 6443; listen 443; proxy_pass kubernetes; } } EOF Dockerfile Create Dockerfile to build nginx load balancer docker image\n# On host $ cd ~/kubernetes-the-hard-way $ cat \u0026lt;\u0026lt;EOF | tee Dockerfile FROM nginx:latest MAINTAINER Veerendra Kakumanu RUN mkdir -p /etc/nginx/tcpconf.d \u0026amp;\u0026amp; echo \u0026#34;include /etc/nginx/tcpconf.d/*;\u0026#34; \u0026gt;\u0026gt; /etc/nginx/nginx.conf COPY kubernetes.conf /etc/nginx/tcpconf.d/kubernetes.conf EOF Build and launch the container\n# On host $ cd ~/kubernetes-the-hard-way $ sudo docker build -t nginx_proxy . $ sudo docker run -it -d -h proxy --net br0 --ip 10.200.1.15 nginx-proxy Verification curl the HTTPS endpoint of load balancer(nginx docker container) which forwards the requests to the controller node with certificate.\n## On host $ KUBERNETES_PUBLIC_ADDRESS=10.200.1.15 $ curl --cacert ca.pem https://${KUBERNETES_PUBLIC_ADDRESS}:6443/version If everything is good, you should see output like below.\nIn this post, we have successfully provisioned controller nodes and load balancers. We will bootstrap the worker nodes in next post\n","permalink":"https://veerendra2.github.io/posts/kubernetes-the-hard-way-2/","summary":"Welcome back to \u0026ldquo;Kubernetes-The Hard Way With Docker \u0026amp; Flannel\u0026rdquo; series part 2. In previous post we have provisioned compute resources, generated certificates and kubeconfig files. In this post, we will install and configure controller nodes\n6. Bootstrapping the etcd Cluster etcd is a consistent and highly-available key value storage DB. Kubernetes stores all cluster data in etcd via api-server. In this section we will install and configure etcd on all controller nodes.","title":"Kubernetes-The Hard Way With Docker \u0026 Flannel (Part 2)"},{"content":"Welcome to the final part of \u0026ldquo;Kubernetes-The Hard Way With Docker \u0026amp; Flannel\u0026rdquo; series. In part-1, we discussed our cluster architecture, provisioned compute resources, generated certificates and kubeconfig. In part-2, we have bootstrapped controller nodes.\nIn this post, we will bootstrap worker nodes and at the end, perform smoke test on the cluster\n9. Bootstrapping the Kubernetes Worker Nodes As the title of this post \u0026ldquo;Kubernetes The Hard Way With Docker \u0026amp; Flannel\u0026rdquo;, what we are going to do now is different from Kelsey Hightower\u0026rsquo;s Kubernetes The Hard Way tutorial i.e. container runtime interface is docker instead of containerd\n*NOTE: The below commands must run on all worker nodes\nInstall below packages. conntack is required for iptables, since it tracks the connections for K8s services\n## On worker nodes $ { sudo apt-get update sudo apt-get -y install socat conntrack ipset } Install docker You can follow official docs to install docker on ubuntu\nKubelet Configuration Move certificate files to kubernetes directory\n## On worker nodes $ { sudo mv ${HOSTNAME}-key.pem ${HOSTNAME}.pem /var/lib/kubelet/ sudo mv ${HOSTNAME}.kubeconfig /var/lib/kubelet/kubeconfig sudo mv ca.pem /var/lib/kubernetes/ } Create kubelet configuration file\n## On worker nodes $ cat \u0026lt;\u0026lt;EOF | sudo tee /var/lib/kubelet/kubelet-config.yaml kind: KubeletConfiguration apiVersion: kubelet.config.k8s.io/v1beta1 authentication: anonymous: enabled: false webhook: enabled: true x509: clientCAFile: \u0026#34;/var/lib/kubernetes/ca.pem\u0026#34; authorization: mode: Webhook clusterDomain: \u0026#34;cluster.local\u0026#34; clusterDNS: - \u0026#34;10.32.0.10\u0026#34; podCIDR: \u0026#34;10.100.0.0/16\u0026#34; #resolvConf: \u0026#34;/run/systemd/resolve/resolv.conf\u0026#34; runtimeRequestTimeout: \u0026#34;15m\u0026#34; tlsCertFile: \u0026#34;/var/lib/kubelet/n1.pem\u0026#34; tlsPrivateKeyFile: \u0026#34;/var/lib/kubelet/n1-key.pem\u0026#34; EOF Create a kubelet systemd unit file. Below you can notice I have specified --docker* flag which indicates that kubelet intracts with docker daemon\n## On worker nodes $ cat \u0026lt;\u0026lt;EOF | sudo tee /etc/systemd/system/kubelet.service [Unit] Description=Kubernetes Kubelet Documentation=https://github.com/kubernetes/kubernetes After=containerd.service Requires=containerd.service [Service] ExecStart=/usr/local/bin/kubelet \\ --config=/var/lib/kubelet/kubelet-config.yaml \\ --docker=unix:///var/run/docker.sock \\ --docker-endpoint=unix:///var/run/docker.sock \\ --image-pull-progress-deadline=2m \\ --network-plugin=cni \\ --kubeconfig=/var/lib/kubelet/kubeconfig \\ --register-node=true \\ --v=2 Restart=on-failure RestartSec=5 [Install] WantedBy=multi-user.target EOF Kube Proxy Configuration Move kubeconfig to kubernetes directory\n## On worker nodes $ sudo mv kube-proxy.kubeconfig /var/lib/kube-proxy/kubeconfig Create kube-proxy configuration file\n## On worker nodes $ cat \u0026lt;\u0026lt;EOF | sudo tee /var/lib/kube-proxy/kube-proxy-config.yaml kind: KubeProxyConfiguration apiVersion: kubeproxy.config.k8s.io/v1alpha1 clientConnection: kubeconfig: \u0026#34;/var/lib/kube-proxy/kubeconfig\u0026#34; mode: \u0026#34;iptables\u0026#34; clusterCIDR: \u0026#34;10.100.0.0/16\u0026#34; EOF Create kube-proxy systemd unit file\n## On worker nodes $ cat \u0026lt;\u0026lt;EOF | sudo tee /etc/systemd/system/kube-proxy.service [Unit] Description=Kubernetes Kube Proxy Documentation=https://github.com/kubernetes/kubernetes [Service] ExecStart=/usr/local/bin/kube-proxy \\\\ --config=/var/lib/kube-proxy/kube-proxy-config.yaml Restart=on-failure RestartSec=5 [Install] WantedBy=multi-user.target EOF Start Worker services ## On worker nodes $ { sudo systemctl daemon-reload sudo systemctl enable kubelet kube-proxy sudo systemctl start kubelet kube-proxy } Verification Once worker services configuration is done on all worker nodes, get nodes list like below command in any controller node\n10. Configuring kubectl for Remote Access In this section, we will generate a kubeconfig file for admin user. The kubeconfig file requires Kubernetes API server IP which is nginx load balancer docker container’s IP\n## On host $ { KUBERNETES_PUBLIC_ADDRESS=`cat nginx_proxy.txt | awk \u0026#39;{print $2}\u0026#39;` kubectl config set-cluster kubernetes-the-hard-way \\ --certificate-authority=ca.pem \\ --embed-certs=true \\ --server=https://${KUBERNETES_PUBLIC_ADDRESS}:6443 kubectl config set-credentials admin \\ --client-certificate=admin.pem \\ --client-key=admin-key.pem kubectl config set-context kubernetes-the-hard-way \\ --cluster=kubernetes-the-hard-way \\ --user=admin kubectl config use-context kubernetes-the-hard-way } Verification Check health of the remote Kubernetes cluster List the nodes in the remote Kubernetes cluster Provisioning CNI In this section, we will set up CNI i.e Flannel as the title of this blog post says.\n**If you want to know other CNIs and there performances, check Alexis Ducastel\u0026rsquo;s post here\nFirst login into worker nodes and enable ip forwarding\n## On worker nodes $ sudo sysctl net.ipv4.conf.all.forwarding=1 Get kube-flannel.yml from coreos\u0026rsquo;s flannel github repo\n## On host $ kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml Wait for few seconds and verify flannel daemonset status\n$ kubectl get daemonsets -n kube-system Once pods are up, we have to test pod networking that they can connect each other\nFor that, we will deploy nginx deployment with 2 replicas and a busybox pod. Then we will try to curl nginx home page from busybox via nginx\u0026rsquo;s POD IP\nCreate nginx deployment with 2 replicas\n$ cat \u0026lt;\u0026lt; EOF | kubectl apply -f - apiVersion: apps/v1 kind: Deployment metadata: name: nginx spec: selector: matchLabels: run: nginx replicas: 2 template: metadata: labels: run: nginx spec: containers: - name: my-nginx image: nginx ports: - containerPort: 80 EOF Create service for the deployment\n$ kubectl expose deployment/nginx Get nginx pods IP\n$ kubectl get ep nginx Now let curl nginx home of nginx pods\n$ kubectl run busybox --image=odise/busybox-curl --command -- sleep 3600 $ POD_NAME=$(kubectl get pods -l run=busybox -o jsonpath=\u0026#34;{.items[0].metadata.name}\u0026#34;) $ kubectl exec $POD_NAME -- curl \u0026lt;first nginx pod IP address\u0026gt; $ kubectl exec $POD_NAME -- curl \u0026lt;second nginx pod IP address\u0026gt; $ kubectl get svc 11. Deploying the DNS Cluster Add-on In this section we will deploy DNS add-on which provides DNS based service discovery. We will use coreDNS as DNS add-on in our K8s\nDeploy core DNS\n$ kubectl apply -f https://storage.googleapis.com/kubernetes-the-hard-way/coredns.yaml Verification Verify core DNS pods are up\n$ kubectl get pods -l k8s-app=kube-dns -n kube-system In order to verify DNS resolution in K8s, we need to create a busybox pod and try nslookup the kubernetes service\nCreate a busybox deployment\n$ kubectl run busybox --image=odise/busybox-curl --command -- sleep 3600 Retrieve the full name of the busybox pod and execute a DNS lookup for the kubernetes service inside the busybox pod\n$ POD_NAME=$(kubectl get pods -l run=busybox -o jsonpath=\u0026#34;{.items[0].metadata.name}\u0026#34;) $ kubectl exec -ti $POD_NAME -- nslookup kubernetes If everything is good, you should see \u0026ldquo;kubernetes\u0026rdquo; name resolution like above\nThat completes our objectives, we have installed necessary components to bring up the kubernetes.You can perform some other smoke test from official Kubernetes The Hard Way\nConclusion It has been a long post for readers. I have modified the official Kubernetes The Hard Way to set up Docker as CRI and Flannel as CNI. So, let\u0026rsquo;s conclude what we have done so far\nProvisioning compute resources in Laptop with kvm hypervisor 2 controllers, 2 computers and nginx docker containers which serves as load balancer. Generated certificates to setup TLS communication between the kubernetes components kubeconfig files generations Provisioning controller and worker nodes with docker and Flannel You can go even further to set up K8s dashboard,K8s logging and Prometheus monitoring, etc. (For starters, you can refer my prometheus-k8s-monitoring)\nReferences https://github.com/kelseyhightower/kubernetes-the-hard-way https://developer.ibm.com/recipes/tutorials/bridge-the-docker-containers-to-external-network/ https://docs.docker.com/config/containers/container-networking/ https://coreos.com/flannel/docs/latest/kubernetes.html https://unix.stackexchange.com/questions/490893/not-able-to-ssh-from-vm-to-vm-via-linux-bridge ","permalink":"https://veerendra2.github.io/posts/kubernetes-the-hard-way-3/","summary":"Welcome to the final part of \u0026ldquo;Kubernetes-The Hard Way With Docker \u0026amp; Flannel\u0026rdquo; series. In part-1, we discussed our cluster architecture, provisioned compute resources, generated certificates and kubeconfig. In part-2, we have bootstrapped controller nodes.\nIn this post, we will bootstrap worker nodes and at the end, perform smoke test on the cluster\n9. Bootstrapping the Kubernetes Worker Nodes As the title of this post \u0026ldquo;Kubernetes The Hard Way With Docker \u0026amp; Flannel\u0026rdquo;, what we are going to do now is different from Kelsey Hightower\u0026rsquo;s Kubernetes The Hard Way tutorial i.","title":"Kubernetes-The Hard Way With Docker \u0026 Flannel (Part 3)"},{"content":"As we all know, enabling HTTPS to endpoints/websites is essential now-a-days. When it comes to Kubernetes, when we expose a service as LoadBalancer, the cloud provider doesn\u0026rsquo;t provide an HTTPS mechanism for the endpoint by default.\nIf we look at the K8s setup that is deployed on AWS(For example kops), there is an actual ELB(Elastic Load Balancer) sits in front of K8s service and load balance the traffic. AWS\u0026rsquo;s ELB is not TLS enabled by default. With help of aws-cli, we can deploy certificates(self-signed) on the load balancer and make the endpoint secure.\nNote that the K8s cluster is deployed on AWS and configured \u0026ldquo;type: LoadBalancer\u0026rdquo; for service which applications can access from outside of the cluster.\nPrerequisites Get cfssl and cfssljson binary files from https://pkg.cfssl.org/ Get aws-cli. Check installation docs Configure aws-cli with aws configure. It should create files like below veeru@ultron:~$ cat ~/.aws/credentials [default] aws_access_key_id = ATIA2HTxxxV5Cqwe aws_secret_access_key = ATIA2HTxxxV5Cqwexxxxxx veeru@ultron:~$ cat ~/.aws/config [default] region = us-east-2 output = text Create certificate $ cat \u0026lt;\u0026lt;EOF \u0026gt;csr_ca.json { \u0026#34;CN\u0026#34;: \u0026#34;My Awesome CA\u0026#34;, \u0026#34;key\u0026#34;: { \u0026#34;algo\u0026#34;: \u0026#34;rsa\u0026#34;, \u0026#34;size\u0026#34;: 2048 }, \u0026#34;names\u0026#34;: [ { \u0026#34;C\u0026#34;: \u0026#34;Westeros\u0026#34;, \u0026#34;L\u0026#34;: \u0026#34;Winterfell\u0026#34;, \u0026#34;O\u0026#34;: \u0026#34;House Stark\u0026#34;, \u0026#34;OU\u0026#34;: \u0026#34;CA Secsr_ca.jsonrvices\u0026#34;, \u0026#34;ST\u0026#34;: \u0026#34;The North\u0026#34; } ] } EOF Generate the CA certificate and private key:\n$ cfssl gencert -initca csr_ca.json | cfssljson -bare ca $ ls ca-key.pem ca.pem Upload your self signed certificate to aws $ aws iam upload-server-certificate --server-certificate-name your-name --certificate-body file://ca.pem --private-key file://ca-key.pem List certificates\n$ aws iam list-server-certificates SERVERCERTIFICATEMETADATALIST arn:aws:iam::xxxxx:server-certificate/your-name 2023-04-30T07:52:00Z / ASCAIxxxxxCHES3FxxIQO cf 2018-05-01T08:17:30Z Specify annotation in Kuberenetes service Edit service with \u0026ldquo;kubectl edit svc {svc-name}\u0026rdquo; or you can also edit with the help of K8s dashboard like me.\n\u0026#34;service.beta.kubernetes.io/aws-load-balancer-ssl-cert\u0026#34;: \u0026#34;arn:aws:iam::xxxxx:server-certificate/your-name\u0026#34; Now you should be able to access the endpoint on https.\nFor example: https://xxxx-xxxx.us-east-2.elb.amazonaws.com:9090/graph Check out other AWS service annotations\n","permalink":"https://veerendra2.github.io/posts/ssl-config-k8s-service-aws/","summary":"As we all know, enabling HTTPS to endpoints/websites is essential now-a-days. When it comes to Kubernetes, when we expose a service as LoadBalancer, the cloud provider doesn\u0026rsquo;t provide an HTTPS mechanism for the endpoint by default.\nIf we look at the K8s setup that is deployed on AWS(For example kops), there is an actual ELB(Elastic Load Balancer) sits in front of K8s service and load balance the traffic. AWS\u0026rsquo;s ELB is not TLS enabled by default.","title":"SSL Configuration for Kubernetes External LoadBalancer - [AWS ELB]"},{"content":"*A blog post that I’m actively collecting “Linux pseudo files info, cheat sheets and tips”\nTips \u0026amp; Tricks How to force a command to return exit code 0 even if the command exited non-zero?\nHow to install dependencies of .deb automatically which failed to install previously?\nExample Solution:\n$ dpkg -i r-base-core_3.3.3-1trusty0_amd64.deb || : \\ \u0026amp;\u0026amp; apt-get --yes --force-yes -o Dpkg::Options::=\u0026#34;--force-confdef\u0026#34; -o Dpkg::Options::=\u0026#34;--force-confold\u0026#34; -f install -y \\ How to traverse directories in shell script?\ncd command should not be used to traverse directories. Remember that each commands in shell script will spawn as individual process unlink programming language, entire script as single process i.e. The scope of cd command is only for the child process, not the parent. By using pushd and popd we can achieve traversing directories.\nExample Solution:\n$ pushd Downloads $ cat download.txt $ popd $ pushd Downloads/movies $ ls $ popd Files: /sys/devices/system/cpu/cpu*/cpufreq/scaling_cur_freq - Real time speed of the CPU(ability to adjust their speed to help in saving on battery/power usage)\n/proc Directory\n/proc/cpuinfo | grep MHz - The absolute (max) CPU speed /proc/sys/net/ipv4/* - Get more info under this directory from kernel.org docs /proc/net/tcp and /proc/net/tcp6 - Get complete info of variables for these files from kernel.org.docs /proc/sysctl https://www.kernel.org/doc/Documentation/sysctl/ https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/4/html/Reference_Guide/s3-proc-sys-net.html\nNetwork related in Linux - Refer kernel.org.doc\nSpecial Device Files /dev/null - Discards all data written to it but reports that the write operation succeeded Read man pages\n/dev/full - Returns the error code ENOSPC (meaning “No space left on device”) on writing Read man pages\n/dev/random - Special file that serves as a blocking pseudorandom number generator. It allows access to environmental noise collected from device drivers and other sources.(Block until additional environmental noise is gathered)Read man\n/dev/urandom - Without block Read man pages\n/dev/zero - Provides as many null characters as are read from it Read More\nudev - Linux dynamic device management Read man pages\nudevadm - command to query the udev database and sysfs Read More Commands/Tools lscpu - Display CPU architecture information\ncat /dev/urandom | tr -dc 'a-zA-Z0-9' | fold -w 40 | head -n 1 - Generates 40 characters long random string\nmtr - mtr combines the functionality of the traceroute and ping programs in a single network diagnostic tool.\nlsblk - Lists block devices\nDirectories /var/lock/ - Store lock files, which are simply files used to indicate that a certain resource (a database, a file, a device) is in use and should not be accessed by another process. Aptitude, for example, locks its database when a package manager is running.\n/var/run - Used to store .pid files, which contain the process id of a running program. This is commonly used in services or programs that need to make their process id available to other processes.\n","permalink":"https://veerendra2.github.io/posts/linux-cheatseets/","summary":"*A blog post that I’m actively collecting “Linux pseudo files info, cheat sheets and tips”\nTips \u0026amp; Tricks How to force a command to return exit code 0 even if the command exited non-zero?\nHow to install dependencies of .deb automatically which failed to install previously?\nExample Solution:\n$ dpkg -i r-base-core_3.3.3-1trusty0_amd64.deb || : \\ \u0026amp;\u0026amp; apt-get --yes --force-yes -o Dpkg::Options::=\u0026#34;--force-confdef\u0026#34; -o Dpkg::Options::=\u0026#34;--force-confold\u0026#34; -f install -y \\ How to traverse directories in shell script?","title":"Linux pseudo files \u0026 cheat sheet"},{"content":"Wireshark is a really great tool for analyzing traffic, whether it could be live traffic on interface or .cap file. The tool enables different types filtering on packets like follow stream, filter by protocol and IP, etc\nIn order to install the latest version of wireshark on Linux, one should build and install from source. Sometimes, building from source is difficult because we have to hunt down the dependencies. That\u0026rsquo;s what I did for this software.\nDepending on your OS and package availability, you may need to install other dependencies. I\u0026rsquo;m using Ubuntu Mate 16 and I found the below are sufficient for me.\nInstall Dependencies $ apt-get install -y \\ qtbase5-dev qtbase5-dev-tools \\ qttools5-dev qttools5-dev-tools \\ qtmultimedia5-dev libqt5svg5-dev \\ libpcap-dev libgcrypt11-dev \\ glib2.0 libgcrypt20-dev \\ libglib2.0-dev ibglib2.0-dev Get the latest tarball from wireshark $ wget https://2.na.dl.wireshark.org/src/wireshark-2.4.5.tar.xz $ tar -xf wireshark-2.4.5.tar.xz $ cd wireshark-2.4.5 Start building $ ./configure $ sudo make install -j2 $ sudo ldconfig $ sudo wireshark ./configure checks dependencies for wireshark in your machines. That\u0026rsquo;s why while running ./configure you may get dependency missing errors. If that is the case, it will show missing dependency packages name i.e. you can google it and install it.\nmake install -j2 will take some time, you can have coffee.(Specify jobs that equals to your number of CPU cores. Ex.-j4 for quad core)\n","permalink":"https://veerendra2.github.io/posts/wireshark-install/","summary":"Wireshark is a really great tool for analyzing traffic, whether it could be live traffic on interface or .cap file. The tool enables different types filtering on packets like follow stream, filter by protocol and IP, etc\nIn order to install the latest version of wireshark on Linux, one should build and install from source. Sometimes, building from source is difficult because we have to hunt down the dependencies. That\u0026rsquo;s what I did for this software.","title":"Build and Install Wireshark"},{"content":"Long back before I worked on Openshift which is really a great container platform tool from Redhat. But installation is not as simple as Kubernetes(relatively). One of the prerequisites for the cluster deployment is Open vSwitch.\nNow let\u0026rsquo;s see how to install Open vSwitch v2.6.1 in RedHat7 step by step\nInstall dependencies\n$ sudo yum install gcc make python-devel openssl-devel \\ kernel-devel graphviz kernel-debug-devel \\ autoconf automake rpm-build redhat-rpm-config \\ libtool Grab OpenvSwitch source from http://www.openvswitch.org/download/\n$ wget http://openvswitch.org/releases/openvswitch-2.6.1.tar.gz $ tar -xf openvswitch-2.6.1.tar.gz $ cd openvswitch-2.6.1 Create a distribution tarball\n$ ./boot.sh $ ./configure $ make dist Now you have distribution tarball(openvswitch-2.6.1.tar.gz) in current directory. Copy this file into the RPM sources directory, e.g.:\n$ cp openvswitch-2.6.1.tar.gz $HOME/rpmbuild/SOURCES Extract distribution tarball openvswitch-2.6.1.tar.gz\n$ tar -xf openvswitch-2.6.1.tar.gz $ cd openvswitch-2.6.1 $ pwd /home/ec2-user/openvswitch-2.6.1/openvswitch-2.6.1 Build Open vSwitch\n$ rpmbuild -bb --without check rhel/openvswitch.spec ... Checking for unpackaged file(s): /usr/lib/rpm/check-files /root/rpmbuild/BUILDROOT/openvswitch-2.6.1-1.x86_64 Wrote: /home/ec2-user/rpmbuild/RPMS/x86_64/openvswitch-2.6.1-1.x86_64.rpm Wrote: /home/ec2-user/rpmbuild/RPMS/x86_64/openvswitch-devel-2.6.1-1.x86_64.rpm Wrote: /home/ec2-user/rpmbuild/RPMS/noarch/openvswitch-selinux-policy-2.6.1-1.noarch.rpm Wrote: /home/ec2-user/rpmbuild/RPMS/x86_64/openvswitch-debuginfo-2.6.1-1.x86_64.rpm ... At the end of building, it will generate openvswitch RPM files.\nInstall the openvswitch RPM files\n$ sudo rpm -i /home/ec2-user/rpmbuild/RPMS/x86_64/openvswitch-2.6.1-1.x86_64.rpm $ sudo rpm -i /home/ec2-user/rpmbuild/RPMS/x86_64/openvswitch-devel-2.6.1-1.x86_64.rpm $ sudo rpm -i /home/ec2-user/rpmbuild/RPMS/noarch/openvswitch-selinux-policy-2.6.1-1.noarch.rpm $ sudo rpm -i /home/ec2-user/rpmbuild/RPMS/x86_64/openvswitch-debuginfo-2.6.1-1.x86_64.rpm Start the openvswitch daemon\n$ sudo service openvswitch start $ sudo service openvswitch status Then you should able to run ovs-appctl --help\nSource http://www.openvswitch.org//support/dist-docs-2.5/INSTALL.RHEL.md.html\n","permalink":"https://veerendra2.github.io/posts/openvswitch-redhat/","summary":"Long back before I worked on Openshift which is really a great container platform tool from Redhat. But installation is not as simple as Kubernetes(relatively). One of the prerequisites for the cluster deployment is Open vSwitch.\nNow let\u0026rsquo;s see how to install Open vSwitch v2.6.1 in RedHat7 step by step\nInstall dependencies\n$ sudo yum install gcc make python-devel openssl-devel \\ kernel-devel graphviz kernel-debug-devel \\ autoconf automake rpm-build redhat-rpm-config \\ libtool Grab OpenvSwitch source from http://www.","title":"Open vSwitch installation on Redhat7 OS"},{"content":"Ok, getting metrics(CPU, Memory \u0026amp; Network) from Windows OS is completely different from Linux. In Linux, people can easily develop scripts to get system metrics by simply reading /proc pesudo files. In fact there are so many open source tools to do this in Linux, like tcollector which is my favourite.\nNow, Let\u0026rsquo;s look at this Telegraf tool and what it does. I found Telegraf tool is really simple, elegant way to collect Windows OS metrics and light weight too, unlike others which some are paid and crappy. This tools doesn\u0026rsquo;t provide any wizard installation to setup, but one has to run a command in Windows powershell to install it as Windows service. It supports multiple TSDB backend storage like Graphite, OpenTSDB, etc but I have tested only with OpenTSDB.\nAs they said in Github repo and I quote\nTelegraf is an agent written in Go for collecting, processing, aggregating, and writing metrics.\nDesign goals are to have a minimal memory footprint with a plugin system so that developers in the community can easily add support for collecting metrics from local or remote services.\nGoto influxdata download portal and download Telegraf zip file\nCreate a folder and name it as Telegraf in C:\\Program Files and extract the .zip content to Telegraf folder (C:\\Program Files\\Telegraf)\nDownload telegraf configuration from here (telegraf.conf) and place it in C:\\Program Files\\Telegraf\nSpecify OpenTSDB server IP in outputs.opentsdb section in the configuration Open \u0026ldquo;Windows PowerShell\u0026rdquo; with administrator rights(Run as administrator) and paste below command to create \u0026ldquo;windows service\u0026rdquo;\nC:\\\u0026#34;Program Files\u0026#34;\\Telegraf\\telegraf.exe --config C:\\\u0026#34;Program Files\u0026#34;\\Telegraf\\telegraf.conf –-service install In Windows Services, you should see Telegraf service. Right-click on the Telegraf service, open \u0026quot;Properties\u0026quot;-\u0026gt; Select \u0026quot;Automatic\u0026quot; for \u0026ldquo;Startup Type\u0026rdquo; and click \u0026ldquo;Start\u0026rdquo; button to start the Telegraf service.\nYou should able to see these metrics in your OpenTSDB\nDocs - https://docs.influxdata.com/telegraf/v1.5/introduction/getting_started/ ","permalink":"https://veerendra2.github.io/posts/windows-metrics-collection/","summary":"Ok, getting metrics(CPU, Memory \u0026amp; Network) from Windows OS is completely different from Linux. In Linux, people can easily develop scripts to get system metrics by simply reading /proc pesudo files. In fact there are so many open source tools to do this in Linux, like tcollector which is my favourite.\nNow, Let\u0026rsquo;s look at this Telegraf tool and what it does. I found Telegraf tool is really simple, elegant way to collect Windows OS metrics and light weight too, unlike others which some are paid and crappy.","title":"Windows OS metrics collection with Telegraf"},{"content":"1. Install Packages Check system is capable of running KVM by running kvm-ok\n$ apt-get install qemu-kvm qemu-system libvirt-bin bridge-utils virt-manager -y Create KVM/Qemu Hard Disk File $ qemu-img create -f raw \u0026lt;name\u0026gt;.img \u0026lt;Size\u0026gt; ## Example $ qemu-img create -f raw ubuntu14-HD.img 10G Then copy the HD file to /var/lib/libvirt/images/ Launch VM with virt-install virt-install --name spinnaker \\ --ram 11096 \\ --vcpus=4 \\ --os-type linux \\ --os-variant=ubuntutrusty \\ --accelerate \\ --nographics -v \\ --disk path=/var/lib/libvirt/images/ubuntu14-HD.img,size=8 \\ --extra-args \u0026#34;console=ttyS0\u0026#34; \\ --location /opt/ubuntu14.iso --force \\ --network bridge:virbr0 Explanation\nCreate bridge virbr0 if it is necessary To know what are --os-variant available, run virt-install --os-variant list Specify --location and --disk locations Specify --ram (By default in MBs) Other Options --boot hd Boot from HD file --force Force to use existing HD that is used by another VM --debug verbose --description Description of VM Connect to console virsh list --all - : List VMs virsh console \u0026lt;name\u0026gt; - : Connect to tty of the VM Note down the IP of the VM once you connect to tty. we can ssh\nNOTE: If console/tty is already being used or active, you can reconnect to that tty by using --extra-args='console=ttyS0' option\nExport VM as .qcow2 $ qemu-img convert -f raw -O qcow2 \u0026lt;source .img file\u0026gt; \u0026lt;destination .qcow2 file\u0026gt; ## Example $ qemu-img convert -f raw -O qcow2 /var/lib/libvirt/images/ubuntu14-HD.img /home/opsmx/spinnaker.qcow2 Commands CheatSheet Command Description virsh list --all Shows all VMs virsh console \u0026lt;VM name\u0026gt; Connect to tty of the VM (If tty is enables) virsh shutdown \u0026lt;VM name\u0026gt; Shutdown the VM vish destroy \u0026lt;VM name\u0026gt; Destroys VM (Won\u0026rsquo;t deletes the VM/ Similar to shutdown) vish undefine \u0026lt;VM name\u0026gt; Deletes the VM (Run after destroy) virsh net-list List the available networks virsh net-edit \u0026lt;net name\u0026gt; Edit the network virt-install --os-variant list Lists OS variants Resource Links https://www.wavether.com/2016/11/import-qcow2-images-into-aws https://docs.openstack.org/image-guide/convert-images.html https://serverfault.com/questions/604862/any-way-to-convert-qcow2-to-ovf https://docs.openstack.org/image-guide/convert-images.html ","permalink":"https://veerendra2.github.io/posts/kvm-hyperviour-cheatsheets/","summary":"1. Install Packages Check system is capable of running KVM by running kvm-ok\n$ apt-get install qemu-kvm qemu-system libvirt-bin bridge-utils virt-manager -y Create KVM/Qemu Hard Disk File $ qemu-img create -f raw \u0026lt;name\u0026gt;.img \u0026lt;Size\u0026gt; ## Example $ qemu-img create -f raw ubuntu14-HD.img 10G Then copy the HD file to /var/lib/libvirt/images/ Launch VM with virt-install virt-install --name spinnaker \\ --ram 11096 \\ --vcpus=4 \\ --os-type linux \\ --os-variant=ubuntutrusty \\ --accelerate \\ --nographics -v \\ --disk path=/var/lib/libvirt/images/ubuntu14-HD.","title":"KVM Hypervisor Cheat Sheets"},{"content":"We think that connecting to a website over HTTPS is secure, which is true(not true sometimes!), but what about DNS queries that you(browser) send?\nSure if we use HTTPS, all your (POST or GET) data is encrypted end-to-end which prevents eavesdropping, MITM attack and have Confidentiality, but again what about DNS queries?\nI got this question back in a while, so after a quick Internet search, I found DNSCrypt protocol which is really cool that I can encrypt DNS queries.\nFirst of all what the heck is DNS? in simple, DNS or Domain Name System is a service that resolves/translates domain \u0026ldquo;name\u0026rdquo; to \u0026ldquo;IP\u0026rdquo; or vice versa. So once you hit google.com in your browser, a DNS query fired to DNS host(for example 8.8.8.8) like asking \u0026ldquo;what is the IP of google.com\u0026rdquo; and gets DNS responses which contains IP of google.com. Now we got the IP of google.com, the browser initiates connection and establishes HTTPS.\nSo, you see these DNS queries are not part of \u0026ldquo;HTTPS\u0026rdquo;. So let\u0026rsquo;s encrypt DNS queries with DNCrypt.\nWhy should we care about \u0026ldquo;DNS queries encryption\u0026rdquo;? Well, sometimes the eavesdroppers are interested in the metadata of communication rather than actual communication.\nWhat is DNSCrypt? DNSCrypt is a protocol that authenticates communications between a DNS client and a DNS resolver. It prevents DNS spoofing. It uses cryptographic signatures to verify that responses originate from the chosen DNS resolver and haven\u0026rsquo;t been tampered with.\nIt is an open specification, with free and open source reference implementations, and it is not affiliated with any company nor organization.\nThere are some points to be noted\nIn order to use this protocol, we should install a package called dnscrypt-proxy Normal name servers(like 8.8.8.8) won\u0026rsquo;t support this protocol. We should use these DNS resolvers dnscrypt-proxy by default binds on loopback interface (127.0.0.1) 53 port. So, I have to change the title configuration. Install dnscrypt-proxy From Ubuntu 16/ Linux Mint 18.x, dnscrypt-proxy is available in the official repo.\nsudo apt-get install dnscrypt-proxy I found a PPA for Ubuntu 14.04 and Linux Mint 17.x\nsudo add-apt-repository ppa:anton+/dnscrypt sudo apt-get update sudo apt-get install dnscrypt-proxy Start dnscrypt-proxy After installation, with --help argument get options and run accordingly. But luckily I created a python script which will do it for you.\nwget -qO dnscrypt.py https://goo.gl/zjZYVR sudo python dnscrypt.py After you run the script, it will list the DNS resolver details like below.(The script downloads resolvers csv and passes this file as argument to `dnscrypt-proxy``)\nSelect one name server. You can see these name servers have options DNSSec \u0026amp; No Logging which provider can logs your queries, choose one accordingly (These options/table header you can\u0026rsquo;t see in above screenshot. You have to scroll up)\nNext, configure your network settings like below\nRestart network (disconnect and connect wifi) and your done!\nTo verify run tcpdump -i any -n port 2053 (Why 2053 port? because in above screenshot I selected 66 option which has 178.216.201.222:2053)\nWhat\u0026rsquo;s happening? Go beyond this script! I created an init script which runs at system boot. So that there is no need to run above script again and again.\nDownload resolvers csv file with \u0026ndash;\u0026gt; python dsncrypt.py -d Specify resolver_name(By default it has soltysiak which has No Logging policy and DNSSec) in the script. sudo wget -O /etc/init.d/encryptdns https://goo.gl/opZ78J sudo chmod +x /etc/init.d/encryptdns sudo update-rc.d encryptdns defaults sudo service encryptdns start Github Repository Link\nhttps://github.com/veerendra2/useless-scripts\nDNSCrypt in Windows Simple DNSCrypt Other resources you can try\nhttps://github.com/jedisct1/dnscrypt-proxy ","permalink":"https://veerendra2.github.io/posts/dns-encrypt/","summary":"We think that connecting to a website over HTTPS is secure, which is true(not true sometimes!), but what about DNS queries that you(browser) send?\nSure if we use HTTPS, all your (POST or GET) data is encrypted end-to-end which prevents eavesdropping, MITM attack and have Confidentiality, but again what about DNS queries?\nI got this question back in a while, so after a quick Internet search, I found DNSCrypt protocol which is really cool that I can encrypt DNS queries.","title":"Encrypt your DNS queries, stay anonymous"},{"content":" A Wi-Fi deauthentication attack is a type of denial-of-service attack that targets communication between a user and a Wi-Fi wireless access point.\n-Wikipedia\nAs you can see, this type of attack is pretty powerful and difficult to detect who is attacking. There are some tools(like “aircrack-ng”) for this attack(You can check the commands here).\nSo, basically the concept is the attacker broadcasts a wifi management “Deauthentication” frame to the victim\u0026rsquo;s devices/PC to tell them to deauthenticate. It is like, “Hey client! Can you please deauthenticate”. Once deauthenticated, then the client will reconnect to AP (Access Point). These types of frames are supposed to send by valid “AP” to its clients, but the attacker can mimic these frames and broadcast in the network.\nInterestingly, the victim’s device/PC could not differentiate between the attacker and valid AP. Here, the attacker creates a “Deauthentication” packet/frame with the source MAC address of valid AP’s MAC address. So, every device thinks, the management frame came from valid AP.\nThe attacker not just sends the frame once, but sends continuously. Things get pretty bad, now the clients are continuously trying to reconnect. In this way, the clients never connect to its valid AP until the attacker stops sending the “deauth” frames.\nSo, how to avoid this attack? Simple, use 802.1w supported routers. Know more about 802.1w and read cisco document here.\nCheck if your wifi network is vulnerable to this attack or not\u0026hellip; I have created a Python script which sends deauth packets using the scapy python module. You can use this script to check if your wifi network is vulnerable or not. Just run the script, select the wifi network that you want to test and if you see a network outage, your wifi is vulnerable!\nDependencies wireless Install aircrack-ng and scapy\n$ sudo apt-get install aircrack-ng -y $ sudo apt-get install python-scapy -y Download and run the script $ wget -O deauth.py https://raw.githubusercontent.com/veerendra2/wifi-deauth-attack/master/deauth.py $ python deauth.py When you run the command, you should see it like below.\nWhen you start the script, it will create a “mon0” interface(A monitoring virtual interface used to send our deauth frames) and observe wifi signals. After a few seconds, it will display near APs and its MAC addresses. Choose one to broadcast the “deauth” frames to that network which results network outage for connected clients to that AP.\nNOTE: Inorder to work a deauthentication attack successfully, you should be near the target network. The deauth packets should reach the connected devices of the target network\nUse my docker image to kick the environment quickly. Github Repository Link - https://github.com/veerendra2/wifi-deauth-attack ","permalink":"https://veerendra2.github.io/posts/wifi-deathentication-attack/","summary":"A Wi-Fi deauthentication attack is a type of denial-of-service attack that targets communication between a user and a Wi-Fi wireless access point.\n-Wikipedia\nAs you can see, this type of attack is pretty powerful and difficult to detect who is attacking. There are some tools(like “aircrack-ng”) for this attack(You can check the commands here).\nSo, basically the concept is the attacker broadcasts a wifi management “Deauthentication” frame to the victim\u0026rsquo;s devices/PC to tell them to deauthenticate.","title":"Wifi Deauthentication Attack"},{"content":" GNU Screen is a terminal multiplexer, a software application that can be used to multiplex several virtual consoles, allowing a user to access multiple separate login sessions inside a single terminal window, or detach and reattach sessions from a terminal. It is useful for dealing with multiple programs from a command line interface, and for separating programs from the session of the Unix shell that started the program, particularly so a remote process continues running even when the user is disconnected. more\n-Wikipedia\nInstall screen $ sudo apt-get install screen Keys/Commands Description screen Enables Screen Ctrl+a and then c Create new screen Ctrl+a and then n Go to next screen Ctrl+a and then p Go to previous screen Ctrl+a and then Shift+s Split screen horizontally Ctrl+a and then Shift+\\ Split screen vertically Ctrl+a and then Tab Traverse between splited screens Ctrl+a and then Shift+x Unsplit screens Ctrl+a and then Esc (Hit Esc, once you are done) Scroll screen Ctrl+a and then d Detach screens screen -r \u0026lt;PID\u0026gt; Reattach screen screen -ls List screens screen -S \u0026lt;session\u0026gt; Attach screen screen -XS \u0026lt;session\u0026gt; quit Kills screen Few more in my Github Gist ","permalink":"https://veerendra2.github.io/posts/gnu-screen-commands/","summary":"GNU Screen is a terminal multiplexer, a software application that can be used to multiplex several virtual consoles, allowing a user to access multiple separate login sessions inside a single terminal window, or detach and reattach sessions from a terminal. It is useful for dealing with multiple programs from a command line interface, and for separating programs from the session of the Unix shell that started the program, particularly so a remote process continues running even when the user is disconnected.","title":"GNU screen commands(Cheat Sheet)"},{"content":"👉 Update on 27-08-2022 Moving to Hugo and other updates! I was very excited to try Jekyll and Github Pages when I heard about it. When I try to install jekyll, I got below error\nroot@veeru:/home/veeru# gem install jekyll bundler Fetching: public_suffix-3.0.1.gem (100%) ERROR: Error installing jekyll: public_suffix requires Ruby version \u0026gt;= 2.1. Fetching: bundler-1.16.1.gem (100%) Successfully installed bundler-1.16.1 1 gem installed Installing ri documentation for bundler-1.16.1... Installing RDoc documentation for bundler-1.16.1... I don\u0026rsquo;t even know what that means(I\u0026rsquo;m not a Ruby guy, so..). Clearly jekyll needs more than Ruby version 2.1, but in Ubuntu 14.04 if you type apt-get install ruby -y you will end up having Ruby 1.9. So let\u0026rsquo;s install Ruby 2.4 like below\nsudo apt-add-repository ppa:brightbox/ruby-ng sudo apt-get update sudo apt-get install ruby2.4 ruby2.4-dev make g++ -y Then install jekyll\n$ gem install jekyll bundler What\u0026rsquo;s next? I found a blog which exactly I was looking for to deploy a website on Github Pages. As Drew Silcock said in the blog, it is better to maintain website source code and compiled websites on the same repository. Just head over to his blog and check the stuff\n","permalink":"https://veerendra2.github.io/posts/jeklly-website/","summary":"👉 Update on 27-08-2022 Moving to Hugo and other updates! I was very excited to try Jekyll and Github Pages when I heard about it. When I try to install jekyll, I got below error\nroot@veeru:/home/veeru# gem install jekyll bundler Fetching: public_suffix-3.0.1.gem (100%) ERROR: Error installing jekyll: public_suffix requires Ruby version \u0026gt;= 2.1. Fetching: bundler-1.16.1.gem (100%) Successfully installed bundler-1.16.1 1 gem installed Installing ri documentation for bundler-1.16.1... Installing RDoc documentation for bundler-1.","title":"Install jekyll in Ubuntu 14.04"},{"content":"“MAC Address Scrambling“- By name itself we can understand, instead of using a burned-in address, the machine uses a random MAC address. The machine/device changes MAC addresses regularly to improve security. MAC address is a 48 bit hexadecimal digit which is burned in every electronic device that has capability of “connectivity” such as mobile devices, smart TV, PC, etc. “Apple” added this feature to iPhones from iOS8 to protect user’s privacy.\nSo, how does a static MAC address cause some security issues? First thing caught in my mind is this\nAccording to Edward Snowden, the National Security Agency has a system that tracks the movements of everyone in a city by monitoring the MAC addresses of their electronic devices. As a result of users being trackable by their devices’ MAC addresses, Apple has started using random MAC addresses in their iOS line of devices while scanning for networks.If random MAC addresses are not used, researchers have confirmed that it is possible to link a real identity to a particular wireless MAC address.\n-wikipedia (https://en.wikipedia.org/wiki/MAC_address)\nAs I said it is “Burned-in”, means it never changes which network you connect unlike IP address. Another possible attack is “Man-in-Middle” with ARP poisoning. I highly recommend you to read wikipedia article: ARP spoofing for better understanding of ARP poisoning. IEEE group also recommends random MAC address for Wifi security. Read this article for more info\nFor Linux, soon will get this feature. But now, I made a script(init script: I know init scripts are not meant for this, but I made it anyway!) which changes MAC address on every time machine boots. Not only on boot, we can change whenever we want with simple commands and can restore to the original or we can go one step further with cron job to schedule the script that changes MAC address for every 1 hour or 30 minutes (Depends on your need).\nIt is a shell script that uses macchanger, which executes every time machine boots thus the interface gets random MAC address every time.\nNOTE: The \u0026ldquo;macchanger\u0026rdquo; or any other script never changes the device’s actual MAC address which is burned on the interface, but macchanger create a proxy which machines uses this proxy MAC address for network communication\nHow to install? Install macchanger\n$ sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install macchanger -y Download and place changer script in /etc/init.d/\n$ wget -q -O /etc/init.d/changer https://goo.gl/tRfoJo Give executable permission\n$ sudo chmod +x /etc/init.d/changer Run update-rc.d\n$ sudo update-rc.d changer defaults Commands $ service changer restore # To restores original MAC MAC Address Restored 0X:XX:XX:27:d8:XX $ sudo service changer new # To assign a new MAC. Note that, interface will go down and up MAC Address Changed Successfully $ service changer show # To shows current MAC Current MAC: 08:00:0c:27:d8:39 NOTE:\nChange the interface in changer after you download, by default the interface is wlan0 There will be network restart when you run service changer new or service changer restore Kali Linux’s latest version(kali-rolling) has this feature. While upgrading(apt-get install upgrade), there is a macchanger prompt asking to enable this feature. ","permalink":"https://veerendra2.github.io/posts/mac-scrambling/","summary":"“MAC Address Scrambling“- By name itself we can understand, instead of using a burned-in address, the machine uses a random MAC address. The machine/device changes MAC addresses regularly to improve security. MAC address is a 48 bit hexadecimal digit which is burned in every electronic device that has capability of “connectivity” such as mobile devices, smart TV, PC, etc. “Apple” added this feature to iPhones from iOS8 to protect user’s privacy.","title":"MAC Address Scrambling in Linux"},{"content":"","permalink":"https://veerendra2.github.io/about/","summary":"","title":"About"},{"content":" Network Blogs Capturing Wireless LAN Packets on Ubuntu with tcpdump and Kismet Linux Bridging Phishing With a Rogue Wi-Fi Access Point Fast DDoS analyzer with sflow/netflow/mirror support China\u0026rsquo;s Man-on-the-Side Attack on GitHub SSH testing tool checks the configuration of given server accessible over internet Infinite possibilities with the Scapy Module An Illustrated Guide to the Kaminsky DNS Vulnerability A penetration tester’s guide to sub-domain enumeration A source for pcap files and malware samples Explanation of how https works Daniels Networking Blog Python for Network Engineers Fuzzing proprietary protocols with Scapy, radamsa and a handful of PCAPs How to Decrypt 802.11 Tutorials for Network Simulator \u0026ldquo;ns\u0026rdquo; The First Few Milliseconds of an HTTPS Connection HTTPS explained with carrier pigeons How To Run Your Own Mail Server Bettercap - MITM attack tool Tcpdump Examples Bluetooth BLEAH-A BLE scanner for \u0026ldquo;smart\u0026rdquo; devices hacking Proxying Bluetooth devices for security analysis using btproxy Nike+ FuelBand SE BLE Protocol Reversed Ubertooth - Can sniff some data from Basic Rate (BR) Bluetooth Classic connections. A Bluetooth LE interface for Python Github Projects Wireless MITM WPA attacks Framework for Rogue Wi-Fi Access Point Attack FruityWiFi is a wireless network auditing tool. Tool for sniffing unencrypted wireless probe requests from devices [Rogue Access Point framework for Wi-Fi automatic association attacks and victim-customized phishing](Rogue Access Point framework for Wi-Fi automatic association attacks and victim-customized phishing) This script creates a NATed or Bridged WiFi Access Point Kick devices off your network by performing an ARP Spoof attack A framework for wireless pentesting. Crack WPA/WPA2 Wi-Fi Routers with Airodump-ng and Aircrack-ng/Hashcat Bluetooth Proxy tool DNS DNS over HTTPS Analyze the security of any domain by finding all the information possible. Made in python Domain name permutation engine for detecting typo squatting, phishing and corporate espionage Selective DNS proxy forwarding based on DNS threat blocking providers intelligence DNS Enumeration Script Fast subdomains enumeration tool for penetration testers Open redirect subdomains scanner Analyze the security of any domain by finding all the information possible. Made in python A set of tools for performing reconnaissance on domain names Scan Scrapy, a fast high-level web crawling \u0026amp; scraping framework for Python TCP port scanner, spews SYN packets asynchronously, scanning entire Internet in under 5 minutes. Nikto web server scanner Scan .onion hidden services with nmap using Tor, proxychains and dnsmasq A small TOR Onion Address harvester for checking if the address is available or not. Tool for capturing and replaying live HTTP traffic into a test environment netdiscover Layer 2 network neighbourhood discovery tool that uses scapy SSL/TLS layers for scapy the interactive packet manipulation tool The python-based interactive packet manipulation program \u0026amp; library Python wrapper for tshark, allowing python packet parsing using wireshark dissectors Stores your data in ICMP ping packets TCP/IP packet demultiplexer Python binding of libnetfilter_conntrack Nipe is a script to make Tor Network your default gateway A reverse TCP tunnel let you access target behind NAT or firewall A Tunnel which Turns UDP Traffic into Encrypted UDP/FakeTCP/ICMP Traffic by using Raw Socket Search MAC Address Linux Blogs Boot Run Levels \u0026amp; How to make init scripts Realmode Assembly – Writing bootable stuff Making scripts run at boot time with Debian Writing a Bootloader init script template systemd, Beyond init-Youtube Talk Analyzing the Linux boot process [Write Simple OS from scratch [PDF]]({{ site.url }}/assets/os-dev.pdf) OS Development The little book about OS development How to Make a Computer Operating System Let\u0026rsquo;s Write a Kernel Information about the creation of operating systems Writing OS in Rust Commands htop explained visually with screenshot Explain Shell Learn VIM 30 interesting commands for the Linux shell An Introduction to Linux Permissions 3 Ways to Permanently and Securely Delete Two great uses for the cp command: Bash shortcuts Files Understanding and generating the hash stored in /etc/shadow What is setiud, setgid and sticky bit in Linux? /proc/sys/net/ipv4 /proc/net/tcp and /proc/net/tcp6 /dev/null /dev/full /dev/random /dev/urandom /dev/zero Warden.NET is an easy to use process management library for keeping track of processes on Windows. [Android Internals[PDF]]({{ \u0026ldquo;/assets/android_internals.pdf \u0026quot; | absolute_url }}) A list of reading materials for BPF How Linux CPU Usage Time and Percentage is calculated Removing Your PDF Metadata \u0026amp; Protecting PDF Files Linux Process Hunter Linux Memory Managment Frequently Asked Questions Attack Infrastructure Logging Virtualization Internals Github Projects A toolkit for creating efficient kernel tracing and manipulation programs Tool for in-depth analysis of USB HID devices communication From finding text to search and replace, from sorting to beautifying text and more Programmable completion functions for bash CheatSheets Bash Python Blog How to recover lost Python source code if it\u0026rsquo;s still resident in-memory Cpython Internals: Codewalk through the Python interpreter source codes [Youtube Playlist] Problem Solving with Algorithms and Data Structures using Python Natural Language Processing with Python Python Anti-Patterns Python Plays: Grand Theft Auto V https://pythonprogramming.net/ Pythonic Data Structures and Algorithms An automation tool that models a user’s actions on a terminal. Regx in easy way You Should Learn Regx Let’s Build A Simple Interpreter Python Excel Tutorial: The Definitive Guide C++ Data Structures [Scapy Docs [PDF]]({{ \u0026ldquo;/assets/scapydoc.pdf\u0026rdquo; | absolute_url }}) python-course.eu Github Projects Android Package Inspector - dynamic analysis with api hooks, start unexported activities and more. (Xposed Module) A public list of APIs from round the web. A Python toolbox for building complex digital hardware A collection of (mostly) technical things every software developer should know What happens when\u0026hellip; Command and Rule over your Shell Shutit-Automation framework for programmers A general-purpose fuzzer Minimal examples of data structures and algorithms in Python Python By Examples Security/Privacy Blogs Privacy What Is Intelligent Tracking Prevention and How Does It Work? The Truth About Online Privacy: How Your Data is Collected, Shared, and Sold What is Cookie Syncing and How Does it Work? Webpage tracking only using CSS (and no JS) How to Monitor Mobile App Traffic With Sniffers Python for PenTesters Intro to basic Disassembly \u0026amp; Reverse Engineering Python for Pentesters-pentesteracademy Start Your Own ISP Details of the implementation of Spectre, Attacking secure USB keys, behind the scene How to Install Tripwire IDS (Intrusion Detection System) on Linux Hacker101! Four Ways to Bypass Android SSL Verification and Certificate Pinning Tracing API calls in Burp with Frida Open Source CyberSecurity - n0where.net [Command Injection [PDF]]({{ \u0026ldquo;/assets/Command_Injection_Shell_Injection.pdf\u0026rdquo; | absolute_url }}) [Recon-ng Guid [PDF]]({{ \u0026ldquo;/assets/recon-ng-guide.pdf\u0026rdquo; | absolute_url }}) Android Applications Reversing 101 moveax.me The New zANTI: Mobile Penetration \u0026amp; Security Analysis Toolkit Reverse Engineering Reverse Engineering Basics A Primer Guide to Reverse Engineering Binary patching and intro to assembly with r2 Github Projects WhatsApp Discover Mobile App Pentest cheat sheet ","permalink":"https://veerendra2.github.io/bookmarks/","summary":"Network Blogs Capturing Wireless LAN Packets on Ubuntu with tcpdump and Kismet Linux Bridging Phishing With a Rogue Wi-Fi Access Point Fast DDoS analyzer with sflow/netflow/mirror support China\u0026rsquo;s Man-on-the-Side Attack on GitHub SSH testing tool checks the configuration of given server accessible over internet Infinite possibilities with the Scapy Module An Illustrated Guide to the Kaminsky DNS Vulnerability A penetration tester’s guide to sub-domain enumeration A source for pcap files and malware samples Explanation of how https works Daniels Networking Blog Python for Network Engineers Fuzzing proprietary protocols with Scapy, radamsa and a handful of PCAPs How to Decrypt 802.","title":"My Bookmarks"}]